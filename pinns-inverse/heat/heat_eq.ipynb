{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "MHmwi2oVth23",
        "outputId": "7670a346-6d9b-443a-bc96-a4af30918b29"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import solve_ivp\n",
        "\n",
        "# Define parameters\n",
        "L = 1.0       # Length of the rod\n",
        "Nx = 50       # Number of spatial points\n",
        "dx = L / Nx   # Space step\n",
        "T = 0.2       # Total time\n",
        "Nt = 201     # Number of time steps\n",
        "dt = T / Nt   # Time step\n",
        "alpha = 0.1  # Thermal diffusivity\n",
        "\n",
        "# Stability condition (for explicit scheme)\n",
        "s = alpha * dt / dx**2\n",
        "if s > 0.5:\n",
        "    print(\"Warning: Stability condition violated! Reduce dt or increase dx.\")\n",
        "\n",
        "# Initial condition: Gaussian pulse\n",
        "x = np.linspace(0, L, Nx)\n",
        "u0 = np.exp(-100 * (x - L/2)**2)  # Gaussian initial profile\n",
        "\n",
        "# Boundary conditions (Dirichlet)\n",
        "u0[0] = 0\n",
        "u0[-1] = 0\n",
        "\n",
        "# Function for the right-hand side of the PDE\n",
        "def heat_eq(t, u):\n",
        "    u = u.reshape((Nx,))\n",
        "    du_dt = np.zeros_like(u)\n",
        "    for i in range(1, Nx - 1):\n",
        "        du_dt[i] = alpha * (u[i-1] - 2*u[i] + u[i+1]) / dx**2\n",
        "    return du_dt\n",
        "\n",
        "# Solve the PDE using solve_ivp\n",
        "solution = solve_ivp(heat_eq, [0, T], u0, t_eval=np.linspace(0, T, Nt), method='RK45')\n",
        "\n",
        "# Reshape the solution to match the time and space dimensions\n",
        "u = solution.y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZyAfiqKtk49",
        "outputId": "f74cafe9-d395-4d96-e064-38ec2b9ab1e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 201)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7QHzgMh2_Iah"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import skewnorm\n",
        "\n",
        "noise = skewnorm.rvs(a=1, scale=0.3, size=u.shape)\n",
        "u += noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "J-xGRHHFtq7P",
        "outputId": "059bc127-d65e-45d4-ee60-97873c33cf5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 201/201 [00:00<00:00, 3411.91it/s]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import animation\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "def visualize_burgers(xcrd, data, path):\n",
        "    \"\"\"\n",
        "    This function animates the Burgers equation\n",
        "\n",
        "    Args:\n",
        "    path : path to the desired file\n",
        "    param: PDE parameter of the data shard to be visualized\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots()\n",
        "    ims = []\n",
        "\n",
        "    for i in tqdm(range(data.shape[0])):\n",
        "        if i == 0:\n",
        "            im = ax.plot(xcrd, data[i].squeeze(), animated=True, color=\"blue\")\n",
        "        else:\n",
        "            im = ax.plot(xcrd, data[i].squeeze(), animated=True, color=\"blue\")\n",
        "        ims.append([im[0]])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "\n",
        "    writer = animation.PillowWriter(fps=15, bitrate=1800)\n",
        "    ani.save(path, writer=writer)\n",
        "    plt.close(fig)\n",
        "visualize_burgers(x, u.T, \"a.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be-wZm2buEGV",
        "outputId": "8d86cc1b-cc35-4363-bcf6-ccb79a731e86"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(PINN, self).__init__()\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                (\n",
        "                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n",
        "                    if i % 2 == 0\n",
        "                    else nn.Tanh()\n",
        "                )\n",
        "                for i in range(20)\n",
        "            ]\n",
        "        )\n",
        "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.alpha = nn.Parameter(torch.tensor([0.1], requires_grad=True).to(\"cuda\"))\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def loss_fn(self, x, u):\n",
        "        u_pred = self.forward(x)\n",
        "        return self.loss(u_pred, u)\n",
        "\n",
        "    def residual_loss(self, xtrain, fhat):\n",
        "        x = xtrain[:, 0]\n",
        "        t = xtrain[:, 1]\n",
        "        g = xtrain.clone()\n",
        "        g.requires_grad = True\n",
        "        u_pred = self.forward(g)\n",
        "        u_x_t = torch.autograd.grad(\n",
        "            u_pred, g, torch.ones_like(u_pred), create_graph=True\n",
        "        )[0]\n",
        "        u_x, u_t = u_x_t[:, 0], u_x_t[:, 1]\n",
        "        u_xx = torch.autograd.grad(u_x, g, torch.ones_like(u_x), create_graph=True)[0][\n",
        "            :, 0\n",
        "        ]\n",
        "        residual = u_t - self.alpha * u_xx\n",
        "        return self.loss(residual, fhat)\n",
        "\n",
        "    def total_loss(self, xtrain, utrain, fhat):\n",
        "        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n",
        "\n",
        "    def train_model(self, xtrain, utrain, epochs=1000):\n",
        "        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = self.total_loss(xtrain, utrain, fhat)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss {loss.item()}, alpha {self.alpha.item()}\")\n",
        "\n",
        "\n",
        "\n",
        "model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j9C4dJ7zHzS",
        "outputId": "916ad940-db51-47b7-dddb-795f72c76110"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((201, 50), (201, 50), (201, 50))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = np.linspace(0, 0.2, 201)\n",
        "X, T = np.meshgrid(x, t)\n",
        "u = u.T\n",
        "X.shape, T.shape, u.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2-dyfJ9zZnn",
        "outputId": "8f737930-11de-4601-f3c9-1834aa1e3746"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5000, 2), (5000, 1))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
        "idx = np.random.choice(201*50, 5000, replace=False)\n",
        "xtrain = xtrue[idx, :]\n",
        "utrain = u.flatten()[idx][:, None]\n",
        "xtrain.shape, utrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzQVDCv7z3ZL",
        "outputId": "77b51547-4765-4c54-a2aa-3f63f81a2902"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5000, 2]),\n",
              " torch.Size([10050, 2]),\n",
              " torch.Size([5000, 1]),\n",
              " torch.Size([10050, 1]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "Xtrain = torch.tensor(xtrain, dtype=torch.float32).to(device)\n",
        "Xtrue = torch.tensor(xtrue, dtype=torch.float32).to(device)\n",
        "Utrain = torch.tensor(utrain, dtype=torch.float32).to(device)\n",
        "utrue = u.flatten()[:, None]\n",
        "utrue = torch.tensor(utrue, dtype=torch.float32).to(device)\n",
        "Xtrain.shape, Xtrue.shape, Utrain.shape, utrue.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yijCIV1z0dFg",
        "outputId": "5033b72a-5ee1-4f34-ddce-71692ae0e0b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10000 [00:00<?, ?it/s]/home/shusrith/projects/torch/lib/python3.12/site-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([5000, 1])) that is different to the input size (torch.Size([5000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "  0%|          | 15/10000 [00:00<02:26, 68.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss 0.1652015894651413, alpha 0.10082937777042389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1028/10000 [00:07<01:04, 139.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1000, Loss 0.0666489526629448, alpha 0.0015933114336803555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2030/10000 [00:14<00:56, 140.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2000, Loss 0.0654907301068306, alpha 0.02085476741194725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3029/10000 [00:21<00:49, 139.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3000, Loss 0.06454396992921829, alpha 0.04318173974752426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4016/10000 [00:28<00:42, 140.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4000, Loss 0.06366275995969772, alpha 0.06283532828092575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5027/10000 [00:36<00:35, 139.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5000, Loss 0.06351204961538315, alpha 0.07214439660310745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6028/10000 [00:43<00:28, 139.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6000, Loss 0.06338241696357727, alpha 0.07695745676755905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7023/10000 [00:50<00:21, 138.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7000, Loss 0.06324394047260284, alpha 0.08023656904697418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8018/10000 [00:57<00:14, 139.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8000, Loss 0.06305033713579178, alpha 0.08236825466156006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9026/10000 [01:04<00:07, 138.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9000, Loss 0.06319021433591843, alpha 0.0839734748005867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [01:11<00:00, 138.98it/s]\n"
          ]
        }
      ],
      "source": [
        "model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n",
        "model.train_model(Xtrain, Utrain, epochs=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vBXUIiq0i16",
        "outputId": "7c1c3955-1ae5-4c2c-c514-cb8c65c9ea72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08536027371883392"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.alpha.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkeechkBWduz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
