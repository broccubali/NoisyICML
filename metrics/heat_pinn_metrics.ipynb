{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10627805,
          "sourceType": "datasetVersion",
          "datasetId": 6580247
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "heat-pinn-metrics",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "shusrith_heateq_path = kagglehub.dataset_download('shusrith/heateq')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "6fwl7KQNJ74A",
        "outputId": "4b8b8196-a6a2-4318-cbfb-2b533df61044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shusrith/heateq?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352M/352M [00:05<00:00, 65.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(PINN, self).__init__()\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                (\n",
        "                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n",
        "                    if i % 2 == 0\n",
        "                    else nn.Tanh()\n",
        "                )\n",
        "                for i in range(20)\n",
        "            ]\n",
        "        )\n",
        "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.alpha = nn.Parameter(torch.tensor([0.1], requires_grad=True).to(\"cuda\"))\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=5e-2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def loss_fn(self, x, u):\n",
        "        u_pred = self.forward(x)\n",
        "        return self.loss(u_pred, u)\n",
        "\n",
        "    def residual_loss(self, xtrain, fhat):\n",
        "        x = xtrain[:, 0]\n",
        "        t = xtrain[:, 1]\n",
        "        g = xtrain.clone()\n",
        "        g.requires_grad = True\n",
        "        u_pred = self.forward(g)\n",
        "        u_x_t = torch.autograd.grad(\n",
        "            u_pred, g, torch.ones_like(u_pred), create_graph=True\n",
        "        )[0]\n",
        "        u_x, u_t = u_x_t[:, 0], u_x_t[:, 1]\n",
        "        u_xx = torch.autograd.grad(u_x, g, torch.ones_like(u_x), create_graph=True)[0][\n",
        "            :, 0\n",
        "        ]\n",
        "        residual = u_t - self.alpha * u_xx\n",
        "        return self.loss(residual, fhat)\n",
        "\n",
        "    def total_loss(self, xtrain, utrain, fhat):\n",
        "        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n",
        "\n",
        "    def train_model(self, xtrain, utrain, epochs=1000):\n",
        "        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n",
        "        for epoch in range(epochs):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = self.total_loss(xtrain, utrain, fhat)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss {loss.item()}, alpha {self.alpha.item()}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:34:50.361349Z",
          "iopub.execute_input": "2025-02-07T06:34:50.361817Z",
          "iopub.status.idle": "2025-02-07T06:34:50.371344Z",
          "shell.execute_reply.started": "2025-02-07T06:34:50.361788Z",
          "shell.execute_reply": "2025-02-07T06:34:50.370376Z"
        },
        "id": "hXpx2YMgJ74F"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "h-bnEnX2KlW1",
        "outputId": "fff5ba18-aaf6-44da-afd8-6bd561dc09f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n",
        "print(model)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:34:53.391011Z",
          "iopub.execute_input": "2025-02-07T06:34:53.391317Z",
          "iopub.status.idle": "2025-02-07T06:34:55.635218Z",
          "shell.execute_reply.started": "2025-02-07T06:34:53.391295Z",
          "shell.execute_reply": "2025-02-07T06:34:55.634438Z"
        },
        "id": "z7SSkkDRJ74J",
        "outputId": "c41cee76-163c-470e-ad78-fbefc2a7ee91"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "PINN(\n  (layers): ModuleList(\n    (0): Linear(in_features=2, out_features=20, bias=True)\n    (1): Tanh()\n    (2): Linear(in_features=20, out_features=20, bias=True)\n    (3): Tanh()\n    (4): Linear(in_features=20, out_features=20, bias=True)\n    (5): Tanh()\n    (6): Linear(in_features=20, out_features=20, bias=True)\n    (7): Tanh()\n    (8): Linear(in_features=20, out_features=20, bias=True)\n    (9): Tanh()\n    (10): Linear(in_features=20, out_features=20, bias=True)\n    (11): Tanh()\n    (12): Linear(in_features=20, out_features=20, bias=True)\n    (13): Tanh()\n    (14): Linear(in_features=20, out_features=20, bias=True)\n    (15): Tanh()\n    (16): Linear(in_features=20, out_features=20, bias=True)\n    (17): Tanh()\n    (18): Linear(in_features=20, out_features=20, bias=True)\n    (19): Tanh()\n    (20): Linear(in_features=20, out_features=1, bias=True)\n  )\n  (loss): MSELoss()\n)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "L = 1.0\n",
        "Nx = 50\n",
        "dx = L / Nx\n",
        "T = 0.2\n",
        "Nt = 500\n",
        "dt = T / Nt\n",
        "x = np.linspace(0, L, Nx)\n",
        "t = np.linspace(0, T, Nt)\n",
        "x.shape, t.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:35:41.356263Z",
          "iopub.execute_input": "2025-02-07T06:35:41.356774Z",
          "iopub.status.idle": "2025-02-07T06:35:41.363568Z",
          "shell.execute_reply.started": "2025-02-07T06:35:41.356743Z",
          "shell.execute_reply": "2025-02-07T06:35:41.36263Z"
        },
        "id": "CY2GTmWGJ74M",
        "outputId": "d2449015-8316-4cc2-9dbd-d4325472d110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50,), (500,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "X, T = np.meshgrid(x, t)\n",
        "xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
        "device = \"cuda\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:35:45.970812Z",
          "iopub.execute_input": "2025-02-07T06:35:45.971101Z",
          "iopub.status.idle": "2025-02-07T06:35:45.976198Z",
          "shell.execute_reply.started": "2025-02-07T06:35:45.971079Z",
          "shell.execute_reply": "2025-02-07T06:35:45.975192Z"
        },
        "id": "kqe0Ao7BJ74R"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "def loadAndPrep(u):\n",
        "    idx = np.random.choice(u.flatten().shape[0], 10000, replace=False)\n",
        "    global xtrue\n",
        "    xtrain = xtrue[idx, :]\n",
        "    utrain = u.flatten()[idx][:, None]\n",
        "    xtrain = torch.tensor(xtrain, dtype=torch.float32, device=device)\n",
        "    xtrue = torch.tensor(xtrue, dtype=torch.float32, device=device)\n",
        "    utrain = torch.tensor(utrain, dtype=torch.float32, device=device)\n",
        "    return xtrain, utrain"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:35:48.500902Z",
          "iopub.execute_input": "2025-02-07T06:35:48.501242Z",
          "iopub.status.idle": "2025-02-07T06:35:48.506839Z",
          "shell.execute_reply.started": "2025-02-07T06:35:48.501215Z",
          "shell.execute_reply": "2025-02-07T06:35:48.505885Z"
        },
        "id": "nXobZ5eiJ74T"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "def trainAndLog(u):\n",
        "    xtrain, utrain = loadAndPrep(u)\n",
        "    model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n",
        "    loss = model.train_model(xtrain, utrain, epochs=15000)\n",
        "    alpha = model.alpha.item()\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    return alpha, loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:35:51.290809Z",
          "iopub.execute_input": "2025-02-07T06:35:51.291157Z",
          "iopub.status.idle": "2025-02-07T06:35:51.2963Z",
          "shell.execute_reply.started": "2025-02-07T06:35:51.291129Z",
          "shell.execute_reply": "2025-02-07T06:35:51.295467Z"
        },
        "id": "hlZf7rfjJ74X"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:32:44.783065Z",
          "iopub.execute_input": "2025-02-07T06:32:44.78338Z",
          "iopub.status.idle": "2025-02-07T06:32:44.913914Z",
          "shell.execute_reply.started": "2025-02-07T06:32:44.783358Z",
          "shell.execute_reply": "2025-02-07T06:32:44.91281Z"
        },
        "id": "rvN1bAneJ74Z"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "\n",
        "random.seed(69)\n",
        "d = {}\n",
        "with h5py.File(\"/root/.cache/kagglehub/datasets/shusrith/heateq/versions/1/data.h5\", \"r\") as f:\n",
        "    a = random.choices(list(f.keys()), k=50)\n",
        "    n = 0\n",
        "    for i in a:\n",
        "        print(n)\n",
        "        d[i] = []\n",
        "        e = f[i][\"alpha\"][()]\n",
        "        print(e)\n",
        "        d[i].append({\"alpha\" : e})\n",
        "        uclean = f[i][\"u\"][:].T\n",
        "        pred, loss = trainAndLog(uclean)\n",
        "        d[i].append({\"clean\" : [{\"predicted\" : pred, \"loss\" : loss}]})\n",
        "        unoisy = f[i][\"u_noisy\"][:]\n",
        "        pred, loss = trainAndLog(unoisy)\n",
        "        d[i].append({\"noisy\": [{\"predicted\" : pred, \"loss\" : loss}]})\n",
        "        n += 1\n",
        "        with open(\"results.json\", \"w\") as g:\n",
        "            json.dump(d, g)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-07T06:38:58.460825Z",
          "iopub.execute_input": "2025-02-07T06:38:58.461129Z",
          "iopub.status.idle": "2025-02-07T06:40:47.852781Z",
          "shell.execute_reply.started": "2025-02-07T06:38:58.461107Z",
          "shell.execute_reply": "2025-02-07T06:40:47.851481Z"
        },
        "id": "8NfBhoGNJ74c",
        "outputId": "cb04b4d0-8459-4096-a915-6e275c7589f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0.4469201134477532\n",
            "Epoch 0, Loss 0.14404895901679993, alpha 0.09904533624649048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-247b4b8569b6>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xtrain = torch.tensor(xtrain, dtype=torch.float32, device=device)\n",
            "<ipython-input-5-247b4b8569b6>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  xtrue = torch.tensor(xtrue, dtype=torch.float32, device=device)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([10000, 1])) that is different to the input size (torch.Size([10000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000, Loss 0.0029497831128537655, alpha 0.11380869150161743\n",
            "Epoch 2000, Loss 0.0022630449384450912, alpha 0.19058184325695038\n",
            "Epoch 3000, Loss 0.0019271105993539095, alpha 0.24109554290771484\n",
            "Epoch 4000, Loss 0.0017500118119642138, alpha 0.2715674042701721\n",
            "Epoch 5000, Loss 0.001588989864103496, alpha 0.29526445269584656\n",
            "Epoch 6000, Loss 0.0024964483454823494, alpha 0.31385985016822815\n",
            "Epoch 7000, Loss 0.0013756247935816646, alpha 0.32687750458717346\n",
            "Epoch 8000, Loss 0.0012977550504729152, alpha 0.33711546659469604\n",
            "Epoch 9000, Loss 0.0012384055880829692, alpha 0.3440559208393097\n",
            "Epoch 10000, Loss 0.0011868656147271395, alpha 0.3487817645072937\n",
            "Epoch 11000, Loss 0.0011456965003162622, alpha 0.3519802689552307\n",
            "Epoch 12000, Loss 0.0011563899461179972, alpha 0.35475292801856995\n",
            "Epoch 13000, Loss 0.0011232774704694748, alpha 0.3568335771560669\n",
            "Epoch 14000, Loss 0.0010504674864932895, alpha 0.3584868609905243\n",
            "Epoch 0, Loss 0.23612645268440247, alpha 0.1009959951043129\n",
            "Epoch 1000, Loss 0.12161687761545181, alpha 0.4053245186805725\n",
            "Epoch 2000, Loss 0.12111330777406693, alpha 1.2442896366119385\n",
            "Epoch 3000, Loss 0.12051616609096527, alpha 1.3163213729858398\n",
            "Epoch 4000, Loss 0.12029730528593063, alpha 1.361806869506836\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f1c063fea793>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"clean\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"predicted\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0munoisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"u_noisy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainAndLog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munoisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"noisy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"predicted\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-80e44d917c7c>\u001b[0m in \u001b[0;36mtrainAndLog\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadAndPrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-ef6a8744d075>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, xtrain, utrain, epochs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "1vrCoc7kJ74g"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}