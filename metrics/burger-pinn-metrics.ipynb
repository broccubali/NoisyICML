{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","name":"burger-pinn-metrics","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10602798,"sourceType":"datasetVersion","datasetId":6553954}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# pinn class","metadata":{"id":"oj6BZ7YFbcg6"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\n\nclass PINN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(PINN, self).__init__()\n        self.layers = nn.ModuleList(\n            [\n                (\n                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n                    if i % 2 == 0\n                    else nn.Tanh()\n                )\n                for i in range(20)\n            ]\n        )\n        self.layers.append(nn.Linear(hidden_size, output_size))\n        self.loss = nn.MSELoss()\n        self.lambda2 = nn.Parameter(\n            torch.tensor([0.01], dtype=torch.float32, device=\"cuda\")\n        )\n        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        self.optimizer.param_groups[0][\"params\"].append(self.lambda2)\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\n    def loss_fn(self, x, u):\n        u_pred = self.forward(x)\n        return self.loss(u_pred, u)\n\n    def residual_loss(self, xtrain, fhat):\n        x = xtrain[:, 0]\n        t = xtrain[:, 1]\n        g = xtrain.clone()\n        g.requires_grad = True\n        u_pred = self.forward(g)\n        u_x_t = torch.autograd.grad(\n            u_pred,\n            g,\n            torch.ones([xtrain.shape[0], 1]).to(\"cuda\"),\n            retain_graph=True,\n            create_graph=True,\n        )[0]\n        u_xx_tt = torch.autograd.grad(\n            u_x_t, g, torch.ones(xtrain.shape).to(\"cuda\"), create_graph=True\n        )[0]\n        u_x = u_x_t[:, [0]]\n        u_t = u_x_t[:, [1]]\n        u_xx = u_xx_tt[:, [0]]\n        return self.loss(u_t + (u_pred * u_x) - (self.lambda2 * u_xx), fhat)\n\n    def total_loss(self, xtrain, utrain, fhat):\n        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n\n    def train_model(self, xtrain, utrain, epochs=1000):\n        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n        for epoch in range(epochs):\n            self.optimizer.zero_grad()\n            loss = self.total_loss(xtrain, utrain, fhat)\n            loss.backward()\n            self.optimizer.step()\n            if epoch % 1000 == 0:\n                print(f\"Epoch {epoch}, Loss {loss.item()}, Lambda2 (Nu) {self.lambda2.item()}\")\n        return loss.item()\n\n\nmodel = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2025-02-07T06:09:10.806580Z","iopub.execute_input":"2025-02-07T06:09:10.806955Z","iopub.status.idle":"2025-02-07T06:09:16.274435Z","shell.execute_reply.started":"2025-02-07T06:09:10.806925Z","shell.execute_reply":"2025-02-07T06:09:16.273504Z"},"id":"7zMBM8RvSZ-B","outputId":"c847dc8b-6a3b-4049-8301-2d9972b7e215","trusted":true},"outputs":[{"name":"stdout","text":"PINN(\n  (layers): ModuleList(\n    (0): Linear(in_features=2, out_features=20, bias=True)\n    (1): Tanh()\n    (2): Linear(in_features=20, out_features=20, bias=True)\n    (3): Tanh()\n    (4): Linear(in_features=20, out_features=20, bias=True)\n    (5): Tanh()\n    (6): Linear(in_features=20, out_features=20, bias=True)\n    (7): Tanh()\n    (8): Linear(in_features=20, out_features=20, bias=True)\n    (9): Tanh()\n    (10): Linear(in_features=20, out_features=20, bias=True)\n    (11): Tanh()\n    (12): Linear(in_features=20, out_features=20, bias=True)\n    (13): Tanh()\n    (14): Linear(in_features=20, out_features=20, bias=True)\n    (15): Tanh()\n    (16): Linear(in_features=20, out_features=20, bias=True)\n    (17): Tanh()\n    (18): Linear(in_features=20, out_features=20, bias=True)\n    (19): Tanh()\n    (20): Linear(in_features=20, out_features=1, bias=True)\n  )\n  (loss): MSELoss()\n)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# load data","metadata":{"id":"rGkiaXm9becD"}},{"cell_type":"code","source":"import jax\nimport jax.numpy as jnp\nfrom math import ceil\ndt_save = 0.01\nini_time = 0.0\nfin_time = 2.0\nnx = 1024\nxL = -1.0\nxR = 1.0\nif_second_order = 1.0\nshow_steps = 100\ndx = (xR - xL) / nx\nxe = jnp.linspace(xL, xR, nx + 1)\nx = xe[:-1] + 0.5 * dx\nit_tot = ceil((fin_time - ini_time) / dt_save) + 1\nt = jnp.arange(it_tot + 1) * dt_save\nx.shape, t.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T06:11:03.315121Z","iopub.execute_input":"2025-02-07T06:11:03.315434Z","iopub.status.idle":"2025-02-07T06:11:03.325137Z","shell.execute_reply.started":"2025-02-07T06:11:03.315406Z","shell.execute_reply":"2025-02-07T06:11:03.324318Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((1024,), (202,))"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"X, T = np.meshgrid(x, t[:-1])\nxtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T06:11:04.320405Z","iopub.execute_input":"2025-02-07T06:11:04.320848Z","iopub.status.idle":"2025-02-07T06:11:04.375490Z","shell.execute_reply.started":"2025-02-07T06:11:04.320809Z","shell.execute_reply":"2025-02-07T06:11:04.374624Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nimport numpy as np\ndef loadAndPrep(u):\n    idx = np.random.choice(201*1024, 10000, replace=False)\n    xtrain = xtrue[idx, :]\n    utrain = u.flatten()[idx][:, None]\n    device = torch.device(\"cuda\")\n    xtrain = torch.tensor(xtrain, dtype=torch.float32, device=device)\n    utrain = torch.tensor(utrain, dtype=torch.float32).to(device)\n    return xtrain, utrain","metadata":{"execution":{"iopub.status.busy":"2025-02-07T06:12:08.296206Z","iopub.execute_input":"2025-02-07T06:12:08.296497Z","iopub.status.idle":"2025-02-07T06:12:08.301388Z","shell.execute_reply.started":"2025-02-07T06:12:08.296476Z","shell.execute_reply":"2025-02-07T06:12:08.300462Z"},"id":"7rMohbkTURuR","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import gc\ndef trainAndLog(u):\n    xtrain, utrain = loadAndPrep(u)\n    model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n    loss = model.train_model(xtrain, utrain, epochs=5000)\n    l = model.lambda2.item()\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    return l, loss","metadata":{"execution":{"iopub.status.busy":"2025-02-07T06:14:11.770573Z","iopub.execute_input":"2025-02-07T06:14:11.771035Z","iopub.status.idle":"2025-02-07T06:14:11.777522Z","shell.execute_reply.started":"2025-02-07T06:14:11.770997Z","shell.execute_reply":"2025-02-07T06:14:11.776487Z"},"id":"2FOOLeOZ1kej","trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import h5py\nimport random\nimport json\n\nrandom.seed(69)\nd = {}\nwith h5py.File(\"/kaggle/input/burgers-clean/simulation_data.h5\", \"r\") as f:\n    a = random.choices(list(f.keys()), k=50)\n    n = 0\n    for i in a[2:5]:\n        print(n)\n        d[i] = []\n        e = f[i][\"epsilon\"][()]\n        print(e / np.pi)\n        d[i].append({\"epsilon\" : e})\n        uclean = f[i][\"clean\"][:]\n        pred, loss = trainAndLog(uclean)\n        d[i].append({\"clean\" : [{\"predicted\" : pred, \"loss\" : loss}]})\n        unoisy = f[i][\"noisy\"][:]\n        pred, loss = trainAndLog(unoisy)\n        d[i].append({\"noisy\": [{\"predicted\" : pred, \"loss\" : loss}]})\n        n += 1\n        with open(\"results.json\", \"w\") as g:\n            json.dump(d, g)","metadata":{"execution":{"iopub.status.busy":"2025-02-07T06:18:40.470220Z","iopub.execute_input":"2025-02-07T06:18:40.470813Z","execution_failed":"2025-02-07T06:22:03.130Z"},"id":"piSIjloX1kek","outputId":"51226dbd-bef9-4e27-f831-647d84e002aa","trusted":true},"outputs":[{"name":"stdout","text":"0\n0.009168248009156534\nEpoch 0, Loss 0.3957606256008148, Lambda2 (Nu) 0.010733280330896378\nEpoch 1000, Loss 0.021998504176735878, Lambda2 (Nu) 0.019452178850769997\nEpoch 2000, Loss 0.017215946689248085, Lambda2 (Nu) 0.016954714432358742\nEpoch 3000, Loss 0.03564969450235367, Lambda2 (Nu) 0.01587020605802536\nEpoch 4000, Loss 0.005353284999728203, Lambda2 (Nu) 0.013688338920474052\nEpoch 0, Loss 0.5446694493293762, Lambda2 (Nu) 0.009262042120099068\nEpoch 1000, Loss 0.05700453370809555, Lambda2 (Nu) 0.02021043561398983\nEpoch 2000, Loss 0.052070263773202896, Lambda2 (Nu) 0.016534147784113884\nEpoch 3000, Loss 0.04937057942152023, Lambda2 (Nu) 0.014715841971337795\nEpoch 4000, Loss 0.046758465468883514, Lambda2 (Nu) 0.013477906584739685\n1\n0.02183573570508892\nEpoch 0, Loss 0.21853750944137573, Lambda2 (Nu) 0.010604371316730976\nEpoch 1000, Loss 0.0013509379932656884, Lambda2 (Nu) 0.021866679191589355\nEpoch 2000, Loss 0.00021913718956056982, Lambda2 (Nu) 0.021478762850165367\nEpoch 3000, Loss 0.0001647724857321009, Lambda2 (Nu) 0.02138676308095455\nEpoch 4000, Loss 0.00014278657909017056, Lambda2 (Nu) 0.02134602889418602\nEpoch 0, Loss 0.1887342780828476, Lambda2 (Nu) 0.010436826385557652\nEpoch 1000, Loss 0.033872656524181366, Lambda2 (Nu) 0.024711664766073227\nEpoch 2000, Loss 0.03123234212398529, Lambda2 (Nu) 0.02135724388062954\n","output_type":"stream"}],"execution_count":null}]}