{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "burger-pinn-metrics"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10602798,
          "sourceType": "datasetVersion",
          "datasetId": 6553954
        }
      ],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shusrith/burgers-clean\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v89pP3AI1keg",
        "outputId": "0d265a09-d622-43f4-e34e-6f72522820fc"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.7).\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/shusrith/burgers-clean/versions/5\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pinn class"
      ],
      "metadata": {
        "id": "oj6BZ7YFbcg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(PINN, self).__init__()\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                (\n",
        "                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n",
        "                    if i % 2 == 0\n",
        "                    else nn.Tanh()\n",
        "                )\n",
        "                for i in range(20)\n",
        "            ]\n",
        "        )\n",
        "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.lambda2 = nn.Parameter(\n",
        "            torch.tensor([0.01], dtype=torch.float32, device=\"cuda\")\n",
        "        )\n",
        "        self.lambda1 = nn.Parameter(\n",
        "            torch.tensor([1.0], dtype=torch.float32, device=\"cuda\")\n",
        "        )\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        self.optimizer.param_groups[0][\"params\"].append(self.lambda1)\n",
        "        self.optimizer.param_groups[0][\"params\"].append(self.lambda2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def loss_fn(self, x, u):\n",
        "        u_pred = self.forward(x)\n",
        "        return self.loss(u_pred, u)\n",
        "\n",
        "    def residual_loss(self, xtrain, fhat):\n",
        "        x = xtrain[:, 0]\n",
        "        t = xtrain[:, 1]\n",
        "        g = xtrain.clone()\n",
        "        g.requires_grad = True\n",
        "        u_pred = self.forward(g)\n",
        "        u_x_t = torch.autograd.grad(\n",
        "            u_pred,\n",
        "            g,\n",
        "            torch.ones([xtrain.shape[0], 1]).to(\"cuda\"),\n",
        "            retain_graph=True,\n",
        "            create_graph=True,\n",
        "        )[0]\n",
        "        u_xx_tt = torch.autograd.grad(\n",
        "            u_x_t, g, torch.ones(xtrain.shape).to(\"cuda\"), create_graph=True\n",
        "        )[0]\n",
        "        u_x = u_x_t[:, [0]]\n",
        "        u_t = u_x_t[:, [1]]\n",
        "        u_xx = u_xx_tt[:, [0]]\n",
        "        return self.loss(u_t + (self.lambda1 * u_pred * u_x) - (self.lambda2 * u_xx), fhat)\n",
        "\n",
        "    def total_loss(self, xtrain, utrain, fhat):\n",
        "        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n",
        "\n",
        "    def train_model(self, xtrain, utrain, epochs=1000):\n",
        "        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n",
        "        for epoch in range(epochs):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = self.total_loss(xtrain, utrain, fhat)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss {loss.item()}, Lambda2 (Nu) {self.lambda2.item()}\")\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "7zMBM8RvSZ-B",
        "outputId": "c847dc8b-6a3b-4049-8301-2d9972b7e215",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T00:43:55.956314Z",
          "iopub.execute_input": "2025-02-06T00:43:55.956668Z",
          "iopub.status.idle": "2025-02-06T00:43:55.972346Z",
          "shell.execute_reply.started": "2025-02-06T00:43:55.95664Z",
          "shell.execute_reply": "2025-02-06T00:43:55.971584Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PINN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=2, out_features=20, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (13): Tanh()\n",
            "    (14): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (15): Tanh()\n",
            "    (16): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (17): Tanh()\n",
            "    (18): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (19): Tanh()\n",
            "    (20): Linear(in_features=20, out_features=1, bias=True)\n",
            "  )\n",
            "  (loss): MSELoss()\n",
            ")\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load data"
      ],
      "metadata": {
        "id": "rGkiaXm9becD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "def loadAndPrep(u):\n",
        "    x = [i for i in range(201)]\n",
        "    t = [i for i in range(1024)]\n",
        "    x = torch.tensor(x, dtype=torch.float32)\n",
        "    t = torch.tensor(t, dtype=torch.float32)\n",
        "    u = torch.tensor(u, dtype=torch.float32)\n",
        "    X, T = np.meshgrid(t, x)\n",
        "    xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
        "    lb = xtrue[0]\n",
        "    ub = xtrue[-1]\n",
        "    idx = np.random.choice(201*1024, 10000, replace=False)\n",
        "    xtrain = xtrue[idx, :]\n",
        "    utrain = u.flatten()[idx][:, None]\n",
        "    device = torch.device(\"cuda\")\n",
        "    xtrain = torch.tensor(xtrain, dtype=torch.float32, device=device)\n",
        "    xtrue = torch.tensor(xtrue, dtype=torch.float32, device=device)\n",
        "    utrain = utrain.to(device)\n",
        "    utrue = u.flatten()[:, None]\n",
        "    return xtrain, xtrue, utrain, utrue"
      ],
      "metadata": {
        "id": "7rMohbkTURuR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T00:38:13.268243Z",
          "iopub.execute_input": "2025-02-06T00:38:13.268563Z",
          "iopub.status.idle": "2025-02-06T00:38:13.274733Z",
          "shell.execute_reply.started": "2025-02-06T00:38:13.268538Z",
          "shell.execute_reply": "2025-02-06T00:38:13.273863Z"
        }
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "def trainAndLog(u):\n",
        "    xtrain, _, utrain, _ = loadAndPrep(u)\n",
        "    model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n",
        "    loss = model.train_model(xtrain, utrain, epochs=10000)\n",
        "    l = model.lambda2.item()\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    return l, loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T00:51:55.464317Z",
          "iopub.execute_input": "2025-02-06T00:51:55.464696Z",
          "iopub.status.idle": "2025-02-06T00:51:55.46939Z",
          "shell.execute_reply.started": "2025-02-06T00:51:55.46467Z",
          "shell.execute_reply": "2025-02-06T00:51:55.468428Z"
        },
        "id": "2FOOLeOZ1kej"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import random\n",
        "random.seed(69)\n",
        "d = {}\n",
        "with h5py.File(\"/root/.cache/kagglehub/datasets/shusrith/burgers-clean/versions/5/simulation_data.h5\", \"r\") as f:\n",
        "    a = random.choices(list(f.keys()), k=100)\n",
        "    n = 0\n",
        "    for i in a[:2]:\n",
        "        print(n)\n",
        "        d[i] = []\n",
        "        d[i].append({\"epsilon\" : f[i][\"epsilon\"][()]})\n",
        "        uclean = f[i][\"clean\"][:]\n",
        "        pred, loss = trainAndLog(uclean)\n",
        "        d[i].append({\"clean\" : [{\"predicted\" : pred, \"loss\" : loss}]})\n",
        "        unoisy = f[i][\"noisy\"][:]\n",
        "        pred, loss = trainAndLog(unoisy)\n",
        "        d[i].append({\"noisy\": [{\"predicted\" : pred, \"loss\" : loss}]})\n",
        "        n += 1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T00:51:56.821686Z",
          "iopub.execute_input": "2025-02-06T00:51:56.821982Z",
          "iopub.status.idle": "2025-02-06T00:52:45.052316Z",
          "shell.execute_reply.started": "2025-02-06T00:51:56.821957Z",
          "shell.execute_reply": "2025-02-06T00:52:45.051564Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piSIjloX1kek",
        "outputId": "51226dbd-bef9-4e27-f831-647d84e002aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss 0.5056760907173157, Lambda2 (Nu) 0.010001664981245995\n",
            "Epoch 1000, Loss 0.48108845949172974, Lambda2 (Nu) 0.1740458458662033\n",
            "Epoch 2000, Loss 0.47685861587524414, Lambda2 (Nu) 0.2158416509628296\n",
            "Epoch 3000, Loss 0.4917241036891937, Lambda2 (Nu) -0.11704258620738983\n",
            "Epoch 4000, Loss 0.49235570430755615, Lambda2 (Nu) -0.04915159195661545\n",
            "Epoch 5000, Loss 0.4916537404060364, Lambda2 (Nu) -0.015493352897465229\n",
            "Epoch 6000, Loss 0.4787796139717102, Lambda2 (Nu) -0.028635742142796516\n",
            "Epoch 7000, Loss 0.49161678552627563, Lambda2 (Nu) 0.0005129274795763195\n",
            "Epoch 8000, Loss 0.49152615666389465, Lambda2 (Nu) 0.009952335618436337\n",
            "Epoch 9000, Loss 0.4948279559612274, Lambda2 (Nu) 0.02076083794236183\n",
            "Epoch 0, Loss 0.5593153238296509, Lambda2 (Nu) 0.009998958557844162\n",
            "Epoch 1000, Loss 0.5098941326141357, Lambda2 (Nu) 0.018785996362566948\n",
            "Epoch 2000, Loss 0.5100711584091187, Lambda2 (Nu) 0.018156906589865685\n",
            "Epoch 3000, Loss 0.5064123272895813, Lambda2 (Nu) 0.00874553993344307\n",
            "Epoch 4000, Loss 0.5050888657569885, Lambda2 (Nu) 0.006322774104773998\n",
            "Epoch 5000, Loss 0.5050839781761169, Lambda2 (Nu) 0.007553229574114084\n",
            "Epoch 6000, Loss 0.5082207918167114, Lambda2 (Nu) 0.010834555141627789\n",
            "Epoch 7000, Loss 0.49792802333831787, Lambda2 (Nu) 0.007793172262609005\n",
            "Epoch 8000, Loss 0.5099385380744934, Lambda2 (Nu) 0.00360361160710454\n",
            "Epoch 9000, Loss 0.5076932311058044, Lambda2 (Nu) 0.007456282153725624\n",
            "1\n",
            "Epoch 0, Loss 0.7867438197135925, Lambda2 (Nu) 0.009993810206651688\n",
            "Epoch 1000, Loss 0.7404719591140747, Lambda2 (Nu) -0.02105693519115448\n",
            "Epoch 2000, Loss 0.7204907536506653, Lambda2 (Nu) -0.1187850683927536\n",
            "Epoch 3000, Loss 0.7157877683639526, Lambda2 (Nu) -0.28837573528289795\n",
            "Epoch 4000, Loss 0.722524881362915, Lambda2 (Nu) -0.16121697425842285\n",
            "Epoch 5000, Loss 0.7267693877220154, Lambda2 (Nu) -0.1232292577624321\n",
            "Epoch 6000, Loss 0.7263079285621643, Lambda2 (Nu) -0.18636274337768555\n",
            "Epoch 7000, Loss 0.69521164894104, Lambda2 (Nu) -0.038964297622442245\n",
            "Epoch 8000, Loss 0.6885618567466736, Lambda2 (Nu) -0.034844327718019485\n",
            "Epoch 9000, Loss 0.6850925087928772, Lambda2 (Nu) -0.017565341666340828\n",
            "Epoch 0, Loss 0.8079865574836731, Lambda2 (Nu) 0.010000156238675117\n",
            "Epoch 1000, Loss 0.7450566291809082, Lambda2 (Nu) -0.18323208391666412\n",
            "Epoch 2000, Loss 0.7596399188041687, Lambda2 (Nu) 0.01074741780757904\n",
            "Epoch 3000, Loss 0.7440541386604309, Lambda2 (Nu) 0.0037449426017701626\n",
            "Epoch 4000, Loss 0.7324557900428772, Lambda2 (Nu) -0.040737684816122055\n",
            "Epoch 5000, Loss 0.7246679067611694, Lambda2 (Nu) -0.027970319613814354\n",
            "Epoch 6000, Loss 0.7615997791290283, Lambda2 (Nu) 0.015960821881890297\n",
            "Epoch 7000, Loss 0.7496547698974609, Lambda2 (Nu) 3.470464071142487e-05\n",
            "Epoch 8000, Loss 0.7490441799163818, Lambda2 (Nu) -0.02933630347251892\n",
            "Epoch 9000, Loss 0.7387726306915283, Lambda2 (Nu) 0.007104518823325634\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/input"
      ],
      "metadata": {
        "id": "gUyxneKt2Jpe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"results.json\", \"w\") as f:\n",
        "    json.dump(d, f)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-06T00:52:54.304717Z",
          "iopub.execute_input": "2025-02-06T00:52:54.30502Z",
          "iopub.status.idle": "2025-02-06T00:52:54.309405Z",
          "shell.execute_reply.started": "2025-02-06T00:52:54.304993Z",
          "shell.execute_reply": "2025-02-06T00:52:54.308527Z"
        },
        "id": "2xmcC-zy1kek"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "43s1UHeO1kel"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
