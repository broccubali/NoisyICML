{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a3203e",
   "metadata": {
    "id": "oj6BZ7YFbcg6",
    "papermill": {
     "duration": 0.002668,
     "end_time": "2025-02-07T09:52:32.407883",
     "exception": false,
     "start_time": "2025-02-07T09:52:32.405215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# pinn class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae775e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T09:52:32.413636Z",
     "iopub.status.busy": "2025-02-07T09:52:32.413302Z",
     "iopub.status.idle": "2025-02-07T09:52:39.097853Z",
     "shell.execute_reply": "2025-02-07T09:52:39.096717Z"
    },
    "id": "7zMBM8RvSZ-B",
    "outputId": "c847dc8b-6a3b-4049-8301-2d9972b7e215",
    "papermill": {
     "duration": 6.689039,
     "end_time": "2025-02-07T09:52:39.099315",
     "exception": false,
     "start_time": "2025-02-07T09:52:32.410276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, lambda2):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                (\n",
    "                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n",
    "                    if i % 2 == 0\n",
    "                    else nn.Tanh()\n",
    "                )\n",
    "                for i in range(20)\n",
    "            ]\n",
    "        )\n",
    "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        self.lambda2 = lambda2\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def loss_fn(self, x, u):\n",
    "        u_pred = self.forward(x)\n",
    "        return self.loss(u_pred, u)\n",
    "\n",
    "    def residual_loss(self, xtrain, fhat):\n",
    "        x = xtrain[:, 0]\n",
    "        t = xtrain[:, 1]\n",
    "        g = xtrain.clone()\n",
    "        g.requires_grad = True\n",
    "        u_pred = self.forward(g)\n",
    "        u_x_t = torch.autograd.grad(\n",
    "            u_pred,\n",
    "            g,\n",
    "            torch.ones([xtrain.shape[0], 1]).to(\"cuda\"),\n",
    "            retain_graph=True,\n",
    "            create_graph=True,\n",
    "        )[0]\n",
    "        u_xx_tt = torch.autograd.grad(\n",
    "            u_x_t, g, torch.ones(xtrain.shape).to(\"cuda\"), create_graph=True\n",
    "        )[0]\n",
    "        u_x = u_x_t[:, [0]]\n",
    "        u_t = u_x_t[:, [1]]\n",
    "        u_xx = u_xx_tt[:, [0]]\n",
    "        return self.loss(u_t + (u_pred * u_x) - (self.lambda2 * u_xx), fhat)\n",
    "\n",
    "    def total_loss(self, xtrain, utrain, fhat):\n",
    "        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n",
    "\n",
    "    def train_model(self, xtrain, utrain, epochs=1000):\n",
    "        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.total_loss(xtrain, utrain, fhat)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss {loss.item()}\")\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8290ef",
   "metadata": {
    "id": "rGkiaXm9becD",
    "papermill": {
     "duration": 0.002048,
     "end_time": "2025-02-07T09:52:39.103830",
     "exception": false,
     "start_time": "2025-02-07T09:52:39.101782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3906c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T09:52:39.108933Z",
     "iopub.status.busy": "2025-02-07T09:52:39.108607Z",
     "iopub.status.idle": "2025-02-07T09:52:42.074904Z",
     "shell.execute_reply": "2025-02-07T09:52:42.074063Z"
    },
    "papermill": {
     "duration": 2.970406,
     "end_time": "2025-02-07T09:52:42.076283",
     "exception": false,
     "start_time": "2025-02-07T09:52:39.105877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024,), (202,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "dt_save = 0.01\n",
    "ini_time = 0.0\n",
    "fin_time = 2.0\n",
    "nx = 1024\n",
    "xL = -1.0\n",
    "xR = 1.0\n",
    "if_second_order = 1.0\n",
    "show_steps = 100\n",
    "dx = (xR - xL) / nx\n",
    "xe = np.linspace(xL, xR, nx + 1)\n",
    "x = xe[:-1] + 0.5 * dx\n",
    "it_tot = ceil((fin_time - ini_time) / dt_save) + 1\n",
    "t = np.arange(it_tot + 1) * dt_save\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "091dcda3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T09:52:42.082652Z",
     "iopub.status.busy": "2025-02-07T09:52:42.082306Z",
     "iopub.status.idle": "2025-02-07T09:52:42.203846Z",
     "shell.execute_reply": "2025-02-07T09:52:42.202873Z"
    },
    "papermill": {
     "duration": 0.126626,
     "end_time": "2025-02-07T09:52:42.205572",
     "exception": false,
     "start_time": "2025-02-07T09:52:42.078946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, T = np.meshgrid(x, t[:-1])\n",
    "xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "xtrue = torch.tensor(xtrue, dtype=torch.float32, device=\"cuda\")\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4d630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T09:52:42.211308Z",
     "iopub.status.busy": "2025-02-07T09:52:42.211081Z",
     "iopub.status.idle": "2025-02-07T09:52:42.215274Z",
     "shell.execute_reply": "2025-02-07T09:52:42.214635Z"
    },
    "id": "7rMohbkTURuR",
    "papermill": {
     "duration": 0.008178,
     "end_time": "2025-02-07T09:52:42.216393",
     "exception": false,
     "start_time": "2025-02-07T09:52:42.208215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def loadAndPrep(u):\n",
    "    idx = np.random.choice(u.flatten().shape[0], 10000, replace=False)\n",
    "    xtrain = xtrue[idx, :]\n",
    "    utrain = u.flatten()[idx][:, None]\n",
    "    utrain = torch.tensor(utrain, dtype=torch.float32).to(device)\n",
    "    return xtrain, utrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "722233da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T09:52:42.221463Z",
     "iopub.status.busy": "2025-02-07T09:52:42.221262Z",
     "iopub.status.idle": "2025-02-07T09:52:42.225353Z",
     "shell.execute_reply": "2025-02-07T09:52:42.224787Z"
    },
    "id": "2FOOLeOZ1kej",
    "papermill": {
     "duration": 0.007912,
     "end_time": "2025-02-07T09:52:42.226486",
     "exception": false,
     "start_time": "2025-02-07T09:52:42.218574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "def trainAndLog(u, e):\n",
    "    xtrain, utrain = loadAndPrep(u)\n",
    "    model = PINN(input_size=2, hidden_size=20, output_size=1, lambda2=e).to(\"cuda\")\n",
    "    loss = model.train_model(xtrain, utrain, epochs=5000)\n",
    "    with torch.no_grad():\n",
    "        pred = model(xtrue).cpu().numpy()\n",
    "    l = np.mean((u.flatten() - pred.flatten())**2)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return l, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "370919be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T09:52:42.231538Z",
     "iopub.status.busy": "2025-02-07T09:52:42.231338Z",
     "iopub.status.idle": "2025-02-07T11:27:05.715013Z",
     "shell.execute_reply": "2025-02-07T11:27:05.714097Z"
    },
    "id": "piSIjloX1kek",
    "outputId": "51226dbd-bef9-4e27-f831-647d84e002aa",
    "papermill": {
     "duration": 5663.488053,
     "end_time": "2025-02-07T11:27:05.716715",
     "exception": false,
     "start_time": "2025-02-07T09:52:42.228662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.021903058643867865\n",
      "Epoch 0, Loss 0.23038563132286072\n",
      "Epoch 1000, Loss 0.01639164239168167\n",
      "Epoch 2000, Loss 0.01437603123486042\n",
      "Epoch 3000, Loss 0.016639266163110733\n",
      "Epoch 4000, Loss 0.012011679820716381\n",
      "Epoch 0, Loss 0.2982577085494995\n",
      "Epoch 1000, Loss 0.04939660057425499\n",
      "Epoch 2000, Loss 0.047684893012046814\n",
      "Epoch 3000, Loss 0.04526390880346298\n",
      "Epoch 4000, Loss 0.045160844922065735\n",
      "1\n",
      "6.105769000963753e-05\n",
      "Epoch 0, Loss 0.3261916935443878\n",
      "Epoch 1000, Loss 0.15796948969364166\n",
      "Epoch 2000, Loss 0.17543300986289978\n",
      "Epoch 3000, Loss 0.16289900243282318\n",
      "Epoch 4000, Loss 0.15132269263267517\n",
      "Epoch 0, Loss 0.36323055624961853\n",
      "Epoch 1000, Loss 0.1796538531780243\n",
      "Epoch 2000, Loss 0.15371429920196533\n",
      "Epoch 3000, Loss 0.2767857015132904\n",
      "Epoch 4000, Loss 0.17790508270263672\n",
      "2\n",
      "0.009168248009156534\n",
      "Epoch 0, Loss 0.4518505334854126\n",
      "Epoch 1000, Loss 0.030698012560606003\n",
      "Epoch 2000, Loss 0.02287222445011139\n",
      "Epoch 3000, Loss 0.008490268141031265\n",
      "Epoch 4000, Loss 0.007861636579036713\n",
      "Epoch 0, Loss 0.44392073154449463\n",
      "Epoch 1000, Loss 0.07780539989471436\n",
      "Epoch 2000, Loss 0.05916168540716171\n",
      "Epoch 3000, Loss 0.05635121837258339\n",
      "Epoch 4000, Loss 0.05436718463897705\n",
      "3\n",
      "0.02183573570508892\n",
      "Epoch 0, Loss 0.21253140270709991\n",
      "Epoch 1000, Loss 0.009943353943526745\n",
      "Epoch 2000, Loss 0.008980909362435341\n",
      "Epoch 3000, Loss 0.008266487158834934\n",
      "Epoch 4000, Loss 0.008034131489694118\n",
      "Epoch 0, Loss 0.26483631134033203\n",
      "Epoch 1000, Loss 0.04088938981294632\n",
      "Epoch 2000, Loss 0.04051085188984871\n",
      "Epoch 3000, Loss 0.03946877643465996\n",
      "Epoch 4000, Loss 0.03904035687446594\n",
      "4\n",
      "0.023270516752570608\n",
      "Epoch 0, Loss 0.21742188930511475\n",
      "Epoch 1000, Loss 0.016611121594905853\n",
      "Epoch 2000, Loss 0.015237294137477875\n",
      "Epoch 3000, Loss 0.014309583231806755\n",
      "Epoch 4000, Loss 0.013476778753101826\n",
      "Epoch 0, Loss 0.27085617184638977\n",
      "Epoch 1000, Loss 0.04877469316124916\n",
      "Epoch 2000, Loss 0.04802689701318741\n",
      "Epoch 3000, Loss 0.04510561004281044\n",
      "Epoch 4000, Loss 0.04394789785146713\n",
      "5\n",
      "0.018359498107300146\n",
      "Epoch 0, Loss 0.32530713081359863\n",
      "Epoch 1000, Loss 0.01674254797399044\n",
      "Epoch 2000, Loss 0.013366758823394775\n",
      "Epoch 3000, Loss 0.0113327382132411\n",
      "Epoch 4000, Loss 0.010882875882089138\n",
      "Epoch 0, Loss 0.4284488558769226\n",
      "Epoch 1000, Loss 0.05259618163108826\n",
      "Epoch 2000, Loss 0.05325065925717354\n",
      "Epoch 3000, Loss 0.046735040843486786\n",
      "Epoch 4000, Loss 0.04606398195028305\n",
      "6\n",
      "0.003569301648081946\n",
      "Epoch 0, Loss 0.14373475313186646\n",
      "Epoch 1000, Loss 0.0025147655978798866\n",
      "Epoch 2000, Loss 0.0018545123748481274\n",
      "Epoch 3000, Loss 0.0014863201649859548\n",
      "Epoch 4000, Loss 0.0014508814783766866\n",
      "Epoch 0, Loss 0.19237466156482697\n",
      "Epoch 1000, Loss 0.03332033008337021\n",
      "Epoch 2000, Loss 0.032690636813640594\n",
      "Epoch 3000, Loss 0.03261572867631912\n",
      "Epoch 4000, Loss 0.03276875987648964\n",
      "7\n",
      "0.024641611224661807\n",
      "Epoch 0, Loss 0.2822539210319519\n",
      "Epoch 1000, Loss 0.020547546446323395\n",
      "Epoch 2000, Loss 0.018039338290691376\n",
      "Epoch 3000, Loss 0.01721915788948536\n",
      "Epoch 4000, Loss 0.016087228432297707\n",
      "Epoch 0, Loss 0.357151061296463\n",
      "Epoch 1000, Loss 0.0545220747590065\n",
      "Epoch 2000, Loss 0.0530635304749012\n",
      "Epoch 3000, Loss 0.05195244401693344\n",
      "Epoch 4000, Loss 0.05012967064976692\n",
      "8\n",
      "0.028202067622015214\n",
      "Epoch 0, Loss 0.2786328196525574\n",
      "Epoch 1000, Loss 0.023895446211099625\n",
      "Epoch 2000, Loss 0.022704795002937317\n",
      "Epoch 3000, Loss 0.021271634846925735\n",
      "Epoch 4000, Loss 0.02061629667878151\n",
      "Epoch 0, Loss 0.2949667274951935\n",
      "Epoch 1000, Loss 0.05656248331069946\n",
      "Epoch 2000, Loss 0.0549955740571022\n",
      "Epoch 3000, Loss 0.05391350015997887\n",
      "Epoch 4000, Loss 0.052970342338085175\n",
      "9\n",
      "0.025611701885464334\n",
      "Epoch 0, Loss 0.27658089995384216\n",
      "Epoch 1000, Loss 0.023790596053004265\n",
      "Epoch 2000, Loss 0.02175804413855076\n",
      "Epoch 3000, Loss 0.02100587636232376\n",
      "Epoch 4000, Loss 0.020000239834189415\n",
      "Epoch 0, Loss 0.3124695420265198\n",
      "Epoch 1000, Loss 0.056390564888715744\n",
      "Epoch 2000, Loss 0.05466968193650246\n",
      "Epoch 3000, Loss 0.053845252841711044\n",
      "Epoch 4000, Loss 0.055340759456157684\n",
      "10\n",
      "0.01892158629632669\n",
      "Epoch 0, Loss 0.29982990026474\n",
      "Epoch 1000, Loss 0.02008083648979664\n",
      "Epoch 2000, Loss 0.015859205275774002\n",
      "Epoch 3000, Loss 0.014273644424974918\n",
      "Epoch 4000, Loss 0.013111811131238937\n",
      "Epoch 0, Loss 0.368997186422348\n",
      "Epoch 1000, Loss 0.05501599237322807\n",
      "Epoch 2000, Loss 0.05245373025536537\n",
      "Epoch 3000, Loss 0.05467771738767624\n",
      "Epoch 4000, Loss 0.047109030187129974\n",
      "11\n",
      "0.018998159228694002\n",
      "Epoch 0, Loss 0.29139289259910583\n",
      "Epoch 1000, Loss 0.01878838799893856\n",
      "Epoch 2000, Loss 0.01849847286939621\n",
      "Epoch 3000, Loss 0.016790900379419327\n",
      "Epoch 4000, Loss 0.015781566500663757\n",
      "Epoch 0, Loss 0.3155478537082672\n",
      "Epoch 1000, Loss 0.052365176379680634\n",
      "Epoch 2000, Loss 0.04965526610612869\n",
      "Epoch 3000, Loss 0.04633006826043129\n",
      "Epoch 4000, Loss 0.04580281674861908\n",
      "12\n",
      "0.00038103053601048543\n",
      "Epoch 0, Loss 0.29482972621917725\n",
      "Epoch 1000, Loss 0.03230736777186394\n",
      "Epoch 2000, Loss 0.02817884460091591\n",
      "Epoch 3000, Loss 0.022623758763074875\n",
      "Epoch 4000, Loss 0.015464263036847115\n",
      "Epoch 0, Loss 0.32043513655662537\n",
      "Epoch 1000, Loss 0.0630367323756218\n",
      "Epoch 2000, Loss 0.05622440204024315\n",
      "Epoch 3000, Loss 0.05036287009716034\n",
      "Epoch 4000, Loss 0.04693608731031418\n",
      "13\n",
      "0.017004191771238276\n",
      "Epoch 0, Loss 0.34315329790115356\n",
      "Epoch 1000, Loss 0.015637077391147614\n",
      "Epoch 2000, Loss 0.012213819660246372\n",
      "Epoch 3000, Loss 0.011637442745268345\n",
      "Epoch 4000, Loss 0.01144361961632967\n",
      "Epoch 0, Loss 0.365325391292572\n",
      "Epoch 1000, Loss 0.05675838142633438\n",
      "Epoch 2000, Loss 0.053450606763362885\n",
      "Epoch 3000, Loss 0.05006713420152664\n",
      "Epoch 4000, Loss 0.04801078885793686\n",
      "14\n",
      "0.010817926257835796\n",
      "Epoch 0, Loss 0.2983609139919281\n",
      "Epoch 1000, Loss 0.01710689626634121\n",
      "Epoch 2000, Loss 0.014490462839603424\n",
      "Epoch 3000, Loss 0.009633337147533894\n",
      "Epoch 4000, Loss 0.008381271734833717\n",
      "Epoch 0, Loss 0.36285045742988586\n",
      "Epoch 1000, Loss 0.043614014983177185\n",
      "Epoch 2000, Loss 0.040081825107336044\n",
      "Epoch 3000, Loss 0.04016563668847084\n",
      "Epoch 4000, Loss 0.03935392200946808\n",
      "15\n",
      "0.011995510034358899\n",
      "Epoch 0, Loss 0.42311370372772217\n",
      "Epoch 1000, Loss 0.02795727178454399\n",
      "Epoch 2000, Loss 0.022213637828826904\n",
      "Epoch 3000, Loss 0.01809091493487358\n",
      "Epoch 4000, Loss 0.013241857290267944\n",
      "Epoch 0, Loss 0.5068373680114746\n",
      "Epoch 1000, Loss 0.061547357589006424\n",
      "Epoch 2000, Loss 0.06062843278050423\n",
      "Epoch 3000, Loss 0.05307541787624359\n",
      "Epoch 4000, Loss 0.048800595104694366\n",
      "16\n",
      "0.010872984608195685\n",
      "Epoch 0, Loss 0.25633704662323\n",
      "Epoch 1000, Loss 0.014983713626861572\n",
      "Epoch 2000, Loss 0.011411162093281746\n",
      "Epoch 3000, Loss 0.008743774145841599\n",
      "Epoch 4000, Loss 0.007530481554567814\n",
      "Epoch 0, Loss 0.39269712567329407\n",
      "Epoch 1000, Loss 0.04939071461558342\n",
      "Epoch 2000, Loss 0.04645407944917679\n",
      "Epoch 3000, Loss 0.042492371052503586\n",
      "Epoch 4000, Loss 0.04032781347632408\n",
      "17\n",
      "0.028202067622015214\n",
      "Epoch 0, Loss 0.30629202723503113\n",
      "Epoch 1000, Loss 0.021968737244606018\n",
      "Epoch 2000, Loss 0.020596060901880264\n",
      "Epoch 3000, Loss 0.025257311761379242\n",
      "Epoch 4000, Loss 0.019292505457997322\n",
      "Epoch 0, Loss 0.3425455391407013\n",
      "Epoch 1000, Loss 0.05707678198814392\n",
      "Epoch 2000, Loss 0.057547908276319504\n",
      "Epoch 3000, Loss 0.05423320084810257\n",
      "Epoch 4000, Loss 0.05303743854165077\n",
      "18\n",
      "0.031319795958366585\n",
      "Epoch 0, Loss 0.33781224489212036\n",
      "Epoch 1000, Loss 0.03000749833881855\n",
      "Epoch 2000, Loss 0.027004040777683258\n",
      "Epoch 3000, Loss 0.025338556617498398\n",
      "Epoch 4000, Loss 0.02350541763007641\n",
      "Epoch 0, Loss 0.41568171977996826\n",
      "Epoch 1000, Loss 0.06972439587116241\n",
      "Epoch 2000, Loss 0.060165759176015854\n",
      "Epoch 3000, Loss 0.058026038110256195\n",
      "Epoch 4000, Loss 0.05636671185493469\n",
      "19\n",
      "0.02780654418428183\n",
      "Epoch 0, Loss 0.10234972834587097\n",
      "Epoch 1000, Loss 0.008345101960003376\n",
      "Epoch 2000, Loss 0.01497886423021555\n",
      "Epoch 3000, Loss 0.008003554306924343\n",
      "Epoch 4000, Loss 0.007827614434063435\n",
      "Epoch 0, Loss 0.1367138922214508\n",
      "Epoch 1000, Loss 0.03827241435647011\n",
      "Epoch 2000, Loss 0.03757613152265549\n",
      "Epoch 3000, Loss 0.037243202328681946\n",
      "Epoch 4000, Loss 0.03712951019406319\n",
      "20\n",
      "0.01884780833706996\n",
      "Epoch 0, Loss 0.19748464226722717\n",
      "Epoch 1000, Loss 0.011080311611294746\n",
      "Epoch 2000, Loss 0.012141639366745949\n",
      "Epoch 3000, Loss 0.009310195222496986\n",
      "Epoch 4000, Loss 0.008195243775844574\n",
      "Epoch 0, Loss 0.21517117321491241\n",
      "Epoch 1000, Loss 0.041460949927568436\n",
      "Epoch 2000, Loss 0.040535371750593185\n",
      "Epoch 3000, Loss 0.040238358080387115\n",
      "Epoch 4000, Loss 0.039346590638160706\n",
      "21\n",
      "0.027499823437111055\n",
      "Epoch 0, Loss 0.3739314675331116\n",
      "Epoch 1000, Loss 0.02277952991425991\n",
      "Epoch 2000, Loss 0.020769920200109482\n",
      "Epoch 3000, Loss 0.01954508386552334\n",
      "Epoch 4000, Loss 0.018053827807307243\n",
      "Epoch 0, Loss 0.30848467350006104\n",
      "Epoch 1000, Loss 0.05719001591205597\n",
      "Epoch 2000, Loss 0.05513179302215576\n",
      "Epoch 3000, Loss 0.05384422093629837\n",
      "Epoch 4000, Loss 0.05280185118317604\n",
      "22\n",
      "0.03166988157190347\n",
      "Epoch 0, Loss 0.4910484850406647\n",
      "Epoch 1000, Loss 0.04557841271162033\n",
      "Epoch 2000, Loss 0.040401361882686615\n",
      "Epoch 3000, Loss 0.03830888867378235\n",
      "Epoch 4000, Loss 0.0471535250544548\n",
      "Epoch 0, Loss 0.5886013507843018\n",
      "Epoch 1000, Loss 0.08131899684667587\n",
      "Epoch 2000, Loss 0.07489147037267685\n",
      "Epoch 3000, Loss 0.07303378731012344\n",
      "Epoch 4000, Loss 0.07022380828857422\n",
      "23\n",
      "0.016815631710165462\n",
      "Epoch 0, Loss 0.45062342286109924\n",
      "Epoch 1000, Loss 0.03515079990029335\n",
      "Epoch 2000, Loss 0.041373465210199356\n",
      "Epoch 3000, Loss 0.028707321733236313\n",
      "Epoch 4000, Loss 0.026691369712352753\n",
      "Epoch 0, Loss 0.5488463044166565\n",
      "Epoch 1000, Loss 0.0700395330786705\n",
      "Epoch 2000, Loss 0.06406687200069427\n",
      "Epoch 3000, Loss 0.05982425436377525\n",
      "Epoch 4000, Loss 0.05511154979467392\n",
      "24\n",
      "0.009942455186440937\n",
      "Epoch 0, Loss 0.4144243896007538\n",
      "Epoch 1000, Loss 0.02423054352402687\n",
      "Epoch 2000, Loss 0.02046825736761093\n",
      "Epoch 3000, Loss 0.0169992633163929\n",
      "Epoch 4000, Loss 0.013363495469093323\n",
      "Epoch 0, Loss 0.432170569896698\n",
      "Epoch 1000, Loss 0.053331341594457626\n",
      "Epoch 2000, Loss 0.04877466708421707\n",
      "Epoch 3000, Loss 0.042632486671209335\n",
      "Epoch 4000, Loss 0.04393228143453598\n",
      "25\n",
      "0.011630259967759987\n",
      "Epoch 0, Loss 0.23928789794445038\n",
      "Epoch 1000, Loss 0.012289106845855713\n",
      "Epoch 2000, Loss 0.007933234795928001\n",
      "Epoch 3000, Loss 0.006915265694260597\n",
      "Epoch 4000, Loss 0.01053947675973177\n",
      "Epoch 0, Loss 0.25851336121559143\n",
      "Epoch 1000, Loss 0.04722483083605766\n",
      "Epoch 2000, Loss 0.04553737863898277\n",
      "Epoch 3000, Loss 0.0449480302631855\n",
      "Epoch 4000, Loss 0.04187748581171036\n",
      "26\n",
      "0.004686252453279073\n",
      "Epoch 0, Loss 0.4695030152797699\n",
      "Epoch 1000, Loss 0.02313491515815258\n",
      "Epoch 2000, Loss 0.019456647336483\n",
      "Epoch 3000, Loss 0.01820303685963154\n",
      "Epoch 4000, Loss 0.014307745732367039\n",
      "Epoch 0, Loss 0.4847709834575653\n",
      "Epoch 1000, Loss 0.07142917811870575\n",
      "Epoch 2000, Loss 0.06307384371757507\n",
      "Epoch 3000, Loss 0.06159500032663345\n",
      "Epoch 4000, Loss 0.057996466755867004\n",
      "27\n",
      "0.030086184682644384\n",
      "Epoch 0, Loss 0.32972925901412964\n",
      "Epoch 1000, Loss 0.03071899153292179\n",
      "Epoch 2000, Loss 0.029069028794765472\n",
      "Epoch 3000, Loss 0.027492299675941467\n",
      "Epoch 4000, Loss 0.027733851224184036\n",
      "Epoch 0, Loss 0.3746050000190735\n",
      "Epoch 1000, Loss 0.05963551253080368\n",
      "Epoch 2000, Loss 0.05562121793627739\n",
      "Epoch 3000, Loss 0.05344847962260246\n",
      "Epoch 4000, Loss 0.05277897045016289\n",
      "28\n",
      "5.3171051151031025e-05\n",
      "Epoch 0, Loss 0.24089708924293518\n",
      "Epoch 1000, Loss 0.08262750506401062\n",
      "Epoch 2000, Loss 0.07595230638980865\n",
      "Epoch 3000, Loss 0.07204149663448334\n",
      "Epoch 4000, Loss 0.07305659353733063\n",
      "Epoch 0, Loss 0.28475338220596313\n",
      "Epoch 1000, Loss 0.14312736690044403\n",
      "Epoch 2000, Loss 0.11080720275640488\n",
      "Epoch 3000, Loss 0.1888553351163864\n",
      "Epoch 4000, Loss 0.12046303600072861\n",
      "29\n",
      "0.02692590294653839\n",
      "Epoch 0, Loss 0.23537449538707733\n",
      "Epoch 1000, Loss 0.020100127905607224\n",
      "Epoch 2000, Loss 0.016955148428678513\n",
      "Epoch 3000, Loss 0.015795450657606125\n",
      "Epoch 4000, Loss 0.01527373306453228\n",
      "Epoch 0, Loss 0.2888333201408386\n",
      "Epoch 1000, Loss 0.05140053480863571\n",
      "Epoch 2000, Loss 0.04941657930612564\n",
      "Epoch 3000, Loss 0.048856426030397415\n",
      "Epoch 4000, Loss 0.04685761034488678\n",
      "30\n",
      "0.012847803862129657\n",
      "Epoch 0, Loss 0.43732813000679016\n",
      "Epoch 1000, Loss 0.027710355818271637\n",
      "Epoch 2000, Loss 0.016970699653029442\n",
      "Epoch 3000, Loss 0.013045985251665115\n",
      "Epoch 4000, Loss 0.012140964157879353\n",
      "Epoch 0, Loss 0.47536805272102356\n",
      "Epoch 1000, Loss 0.06305498629808426\n",
      "Epoch 2000, Loss 0.05859655886888504\n",
      "Epoch 3000, Loss 0.05364527925848961\n",
      "Epoch 4000, Loss 0.04875321313738823\n",
      "31\n",
      "0.009049707205475759\n",
      "Epoch 0, Loss 0.5943942666053772\n",
      "Epoch 1000, Loss 0.041245754808187485\n",
      "Epoch 2000, Loss 0.03224517032504082\n",
      "Epoch 3000, Loss 0.028875697404146194\n",
      "Epoch 4000, Loss 0.025884222239255905\n",
      "Epoch 0, Loss 0.5812875032424927\n",
      "Epoch 1000, Loss 0.07190811634063721\n",
      "Epoch 2000, Loss 0.06380876898765564\n",
      "Epoch 3000, Loss 0.05900045484304428\n",
      "Epoch 4000, Loss 0.053322989493608475\n",
      "32\n",
      "0.02321358552191909\n",
      "Epoch 0, Loss 0.44708511233329773\n",
      "Epoch 1000, Loss 0.03794993832707405\n",
      "Epoch 2000, Loss 0.0329693965613842\n",
      "Epoch 3000, Loss 0.06804753094911575\n",
      "Epoch 4000, Loss 0.028879141435027122\n",
      "Epoch 0, Loss 0.476421058177948\n",
      "Epoch 1000, Loss 0.06541330367326736\n",
      "Epoch 2000, Loss 0.06295886635780334\n",
      "Epoch 3000, Loss 0.05403965339064598\n",
      "Epoch 4000, Loss 0.05301571264863014\n",
      "33\n",
      "0.030184006422183492\n",
      "Epoch 0, Loss 0.4833424687385559\n",
      "Epoch 1000, Loss 0.04515556991100311\n",
      "Epoch 2000, Loss 0.04068891331553459\n",
      "Epoch 3000, Loss 0.03906581178307533\n",
      "Epoch 4000, Loss 0.03611801192164421\n",
      "Epoch 0, Loss 0.5226958990097046\n",
      "Epoch 1000, Loss 0.08813285827636719\n",
      "Epoch 2000, Loss 0.07454104721546173\n",
      "Epoch 3000, Loss 0.07216466218233109\n",
      "Epoch 4000, Loss 0.07119491696357727\n",
      "34\n",
      "0.018729846838383107\n",
      "Epoch 0, Loss 0.11900089681148529\n",
      "Epoch 1000, Loss 0.007576433010399342\n",
      "Epoch 2000, Loss 0.007133231498301029\n",
      "Epoch 3000, Loss 0.006540151312947273\n",
      "Epoch 4000, Loss 0.0061278678476810455\n",
      "Epoch 0, Loss 0.183682382106781\n",
      "Epoch 1000, Loss 0.03699251636862755\n",
      "Epoch 2000, Loss 0.03719373047351837\n",
      "Epoch 3000, Loss 0.03593180328607559\n",
      "Epoch 4000, Loss 0.03567856550216675\n",
      "35\n",
      "0.006538414290476012\n",
      "Epoch 0, Loss 0.42539456486701965\n",
      "Epoch 1000, Loss 0.019022855907678604\n",
      "Epoch 2000, Loss 0.01394493319094181\n",
      "Epoch 3000, Loss 0.008240398950874805\n",
      "Epoch 4000, Loss 0.006177548319101334\n",
      "Epoch 0, Loss 0.35385987162590027\n",
      "Epoch 1000, Loss 0.051714152097702026\n",
      "Epoch 2000, Loss 0.04638960584998131\n",
      "Epoch 3000, Loss 0.04195578396320343\n",
      "Epoch 4000, Loss 0.0404873825609684\n",
      "36\n",
      "0.010085566926049243\n",
      "Epoch 0, Loss 0.18713626265525818\n",
      "Epoch 1000, Loss 0.006868117488920689\n",
      "Epoch 2000, Loss 0.004731413908302784\n",
      "Epoch 3000, Loss 0.004368794150650501\n",
      "Epoch 4000, Loss 0.004249625373631716\n",
      "Epoch 0, Loss 0.27124959230422974\n",
      "Epoch 1000, Loss 0.038799434900283813\n",
      "Epoch 2000, Loss 0.03647708147764206\n",
      "Epoch 3000, Loss 0.03617340326309204\n",
      "Epoch 4000, Loss 0.036083076149225235\n",
      "37\n",
      "0.023822030862999482\n",
      "Epoch 0, Loss 0.3500606417655945\n",
      "Epoch 1000, Loss 0.027112677693367004\n",
      "Epoch 2000, Loss 0.02483562007546425\n",
      "Epoch 3000, Loss 0.023051360622048378\n",
      "Epoch 4000, Loss 0.021265260875225067\n",
      "Epoch 0, Loss 0.3881300687789917\n",
      "Epoch 1000, Loss 0.06502322107553482\n",
      "Epoch 2000, Loss 0.09875907748937607\n",
      "Epoch 3000, Loss 0.06276993453502655\n",
      "Epoch 4000, Loss 0.05827154964208603\n",
      "38\n",
      "0.011022295294245076\n",
      "Epoch 0, Loss 0.49328741431236267\n",
      "Epoch 1000, Loss 0.029180139303207397\n",
      "Epoch 2000, Loss 0.02434883825480938\n",
      "Epoch 3000, Loss 0.02109217643737793\n",
      "Epoch 4000, Loss 0.01743956282734871\n",
      "Epoch 0, Loss 0.5846046209335327\n",
      "Epoch 1000, Loss 0.06339168548583984\n",
      "Epoch 2000, Loss 0.057013045996427536\n",
      "Epoch 3000, Loss 0.05208972096443176\n",
      "Epoch 4000, Loss 0.045818936079740524\n",
      "39\n",
      "0.024597534343882035\n",
      "Epoch 0, Loss 0.4981589615345001\n",
      "Epoch 1000, Loss 0.03707253187894821\n",
      "Epoch 2000, Loss 0.030997544527053833\n",
      "Epoch 3000, Loss 0.02723352424800396\n",
      "Epoch 4000, Loss 0.024689801037311554\n",
      "Epoch 0, Loss 0.49240437150001526\n",
      "Epoch 1000, Loss 0.08010292053222656\n",
      "Epoch 2000, Loss 0.11726483702659607\n",
      "Epoch 3000, Loss 0.0714668408036232\n",
      "Epoch 4000, Loss 0.06848561763763428\n",
      "40\n",
      "0.029179972728268513\n",
      "Epoch 0, Loss 0.1572836935520172\n",
      "Epoch 1000, Loss 0.00976925902068615\n",
      "Epoch 2000, Loss 0.009493215009570122\n",
      "Epoch 3000, Loss 0.013048471882939339\n",
      "Epoch 4000, Loss 0.009246679954230785\n",
      "Epoch 0, Loss 0.15563981235027313\n",
      "Epoch 1000, Loss 0.03980012610554695\n",
      "Epoch 2000, Loss 0.03910526633262634\n",
      "Epoch 3000, Loss 0.039298221468925476\n",
      "Epoch 4000, Loss 0.03984440863132477\n",
      "41\n",
      "0.008790189971769027\n",
      "Epoch 0, Loss 0.442715048789978\n",
      "Epoch 1000, Loss 0.02978050522506237\n",
      "Epoch 2000, Loss 0.02958526834845543\n",
      "Epoch 3000, Loss 0.022658217698335648\n",
      "Epoch 4000, Loss 0.0140606090426445\n",
      "Epoch 0, Loss 0.4643862545490265\n",
      "Epoch 1000, Loss 0.05884658545255661\n",
      "Epoch 2000, Loss 0.05317258834838867\n",
      "Epoch 3000, Loss 0.04633050784468651\n",
      "Epoch 4000, Loss 0.04293571040034294\n",
      "42\n",
      "0.019339994009606943\n",
      "Epoch 0, Loss 0.18991410732269287\n",
      "Epoch 1000, Loss 0.00878410879522562\n",
      "Epoch 2000, Loss 0.008167605847120285\n",
      "Epoch 3000, Loss 0.009168551303446293\n",
      "Epoch 4000, Loss 0.008026348426938057\n",
      "Epoch 0, Loss 0.3312440812587738\n",
      "Epoch 1000, Loss 0.04217495396733284\n",
      "Epoch 2000, Loss 0.04015791788697243\n",
      "Epoch 3000, Loss 0.03901079297065735\n",
      "Epoch 4000, Loss 0.03856838122010231\n",
      "43\n",
      "0.02341738772918682\n",
      "Epoch 0, Loss 0.37795183062553406\n",
      "Epoch 1000, Loss 0.030435027554631233\n",
      "Epoch 2000, Loss 0.02774311788380146\n",
      "Epoch 3000, Loss 0.029347781091928482\n",
      "Epoch 4000, Loss 0.02515804022550583\n",
      "Epoch 0, Loss 0.44323235750198364\n",
      "Epoch 1000, Loss 0.06657707691192627\n",
      "Epoch 2000, Loss 0.0655873492360115\n",
      "Epoch 3000, Loss 0.06359530240297318\n",
      "Epoch 4000, Loss 0.055424585938453674\n",
      "44\n",
      "0.028001185764381244\n",
      "Epoch 0, Loss 0.40123260021209717\n",
      "Epoch 1000, Loss 0.033434703946113586\n",
      "Epoch 2000, Loss 0.03359879553318024\n",
      "Epoch 3000, Loss 0.027622347697615623\n",
      "Epoch 4000, Loss 0.02580099366605282\n",
      "Epoch 0, Loss 0.3990383744239807\n",
      "Epoch 1000, Loss 0.06599024683237076\n",
      "Epoch 2000, Loss 0.06279392540454865\n",
      "Epoch 3000, Loss 0.0610506497323513\n",
      "Epoch 4000, Loss 0.057436712086200714\n",
      "45\n",
      "0.02237144084170321\n",
      "Epoch 0, Loss 0.19452738761901855\n",
      "Epoch 1000, Loss 0.01235283724963665\n",
      "Epoch 2000, Loss 0.011503040790557861\n",
      "Epoch 3000, Loss 0.011349170468747616\n",
      "Epoch 4000, Loss 0.01037518959492445\n",
      "Epoch 0, Loss 0.20150543749332428\n",
      "Epoch 1000, Loss 0.043612852692604065\n",
      "Epoch 2000, Loss 0.04139086604118347\n",
      "Epoch 3000, Loss 0.04029295966029167\n",
      "Epoch 4000, Loss 0.03977378085255623\n",
      "46\n",
      "0.018161870580371137\n",
      "Epoch 0, Loss 0.43107369542121887\n",
      "Epoch 1000, Loss 0.03289582580327988\n",
      "Epoch 2000, Loss 0.028529092669487\n",
      "Epoch 3000, Loss 0.02805127575993538\n",
      "Epoch 4000, Loss 0.02304666116833687\n",
      "Epoch 0, Loss 0.5927469730377197\n",
      "Epoch 1000, Loss 0.06937956809997559\n",
      "Epoch 2000, Loss 0.0654623955488205\n",
      "Epoch 3000, Loss 0.060872334986925125\n",
      "Epoch 4000, Loss 0.057121358811855316\n",
      "47\n",
      "0.03010485647489391\n",
      "Epoch 0, Loss 0.4509909152984619\n",
      "Epoch 1000, Loss 0.04371234402060509\n",
      "Epoch 2000, Loss 0.03983572497963905\n",
      "Epoch 3000, Loss 0.08104157447814941\n",
      "Epoch 4000, Loss 0.03644302114844322\n",
      "Epoch 0, Loss 0.5163290500640869\n",
      "Epoch 1000, Loss 0.0704486295580864\n",
      "Epoch 2000, Loss 0.0662202388048172\n",
      "Epoch 3000, Loss 0.06289108842611313\n",
      "Epoch 4000, Loss 0.06104911118745804\n",
      "48\n",
      "0.03063620194512683\n",
      "Epoch 0, Loss 0.43382781744003296\n",
      "Epoch 1000, Loss 0.03717485070228577\n",
      "Epoch 2000, Loss 0.03290482982993126\n",
      "Epoch 3000, Loss 0.030641134828329086\n",
      "Epoch 4000, Loss 0.02863319031894207\n",
      "Epoch 0, Loss 0.43613407015800476\n",
      "Epoch 1000, Loss 0.07451947778463364\n",
      "Epoch 2000, Loss 0.06996285915374756\n",
      "Epoch 3000, Loss 0.06778824329376221\n",
      "Epoch 4000, Loss 0.06585326790809631\n",
      "49\n",
      "0.01170034298526649\n",
      "Epoch 0, Loss 0.14794597029685974\n",
      "Epoch 1000, Loss 0.0074172429740428925\n",
      "Epoch 2000, Loss 0.005698699504137039\n",
      "Epoch 3000, Loss 0.005220538936555386\n",
      "Epoch 4000, Loss 0.007804353721439838\n",
      "Epoch 0, Loss 0.2670842409133911\n",
      "Epoch 1000, Loss 0.037737421691417694\n",
      "Epoch 2000, Loss 0.03543468564748764\n",
      "Epoch 3000, Loss 0.03498019278049469\n",
      "Epoch 4000, Loss 0.03480438515543938\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(69)\n",
    "d = {}\n",
    "# /kaggle/input/burgers-clean/simulation_data.h5\n",
    "with h5py.File(\"simulation_data.h5\", \"r\") as f:\n",
    "    a = random.choices(list(f.keys()), k=50)\n",
    "    n = 0\n",
    "    for i in a:\n",
    "        print(n)\n",
    "        d[i] = []\n",
    "        e = f[i][\"epsilon\"][()]\n",
    "        print(e / np.pi)\n",
    "        d[i].append({\"epsilon\" : e})\n",
    "        uclean = f[i][\"clean\"][:]\n",
    "        mse, loss = trainAndLog(uclean, e)\n",
    "        d[i].append({\"clean\" : [{\"mse\" : float(mse), \"loss\" : float(loss)}]})\n",
    "        unoisy = f[i][\"noisy\"][:]\n",
    "        mse, loss = trainAndLog(unoisy, e)\n",
    "        d[i].append({\"noisy\": [{\"mse\" : float(mse), \"loss\" : float(loss)}]})\n",
    "        n += 1\n",
    "        with open(\"results.json\", \"w\") as g:\n",
    "            json.dump(d, g)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "burger-pinn-metrics",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6553954,
     "sourceId": 10602798,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5677.563762,
   "end_time": "2025-02-07T11:27:07.425235",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-07T09:52:29.861473",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
