{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","name":"burger-pinn-metrics","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10602798,"sourceType":"datasetVersion","datasetId":6553954}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# pinn class","metadata":{"id":"oj6BZ7YFbcg6"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\n\nclass PINN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(PINN, self).__init__()\n        self.layers = nn.ModuleList(\n            [\n                (\n                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n                    if i % 2 == 0\n                    else nn.Tanh()\n                )\n                for i in range(20)\n            ]\n        )\n        self.layers.append(nn.Linear(hidden_size, output_size))\n        self.loss = nn.MSELoss()\n        self.lambda2 = nn.Parameter(\n            torch.tensor([0.01], dtype=torch.float32, device=\"cuda\")\n        )\n        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        self.optimizer.param_groups[0][\"params\"].append(self.lambda2)\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\n    def loss_fn(self, x, u):\n        u_pred = self.forward(x)\n        return self.loss(u_pred, u)\n\n    def residual_loss(self, xtrain, fhat):\n        x = xtrain[:, 0]\n        t = xtrain[:, 1]\n        g = xtrain.clone()\n        g.requires_grad = True\n        u_pred = self.forward(g)\n        u_x_t = torch.autograd.grad(\n            u_pred,\n            g,\n            torch.ones([xtrain.shape[0], 1]).to(\"cuda\"),\n            retain_graph=True,\n            create_graph=True,\n        )[0]\n        u_xx_tt = torch.autograd.grad(\n            u_x_t, g, torch.ones(xtrain.shape).to(\"cuda\"), create_graph=True\n        )[0]\n        u_x = u_x_t[:, [0]]\n        u_t = u_x_t[:, [1]]\n        u_xx = u_xx_tt[:, [0]]\n        return self.loss(u_t + (u_pred * u_x) - (self.lambda2 * u_xx), fhat)\n\n    def total_loss(self, xtrain, utrain, fhat):\n        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n\n    def train_model(self, xtrain, utrain, epochs=1000):\n        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n        for epoch in range(epochs):\n            self.optimizer.zero_grad()\n            loss = self.total_loss(xtrain, utrain, fhat)\n            loss.backward()\n            self.optimizer.step()\n            if epoch % 1000 == 0:\n                print(f\"Epoch {epoch}, Loss {loss.item()}, Lambda2 (Nu) {self.lambda2.item()}\")\n        return loss.item()\n\n\nmodel = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\nprint(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-02-06T02:22:54.541394Z","iopub.execute_input":"2025-02-06T02:22:54.541814Z","iopub.status.idle":"2025-02-06T02:23:00.141043Z","shell.execute_reply.started":"2025-02-06T02:22:54.541762Z","shell.execute_reply":"2025-02-06T02:23:00.140074Z"},"id":"7zMBM8RvSZ-B","outputId":"c847dc8b-6a3b-4049-8301-2d9972b7e215","trusted":true},"outputs":[{"name":"stdout","text":"PINN(\n  (layers): ModuleList(\n    (0): Linear(in_features=2, out_features=20, bias=True)\n    (1): Tanh()\n    (2): Linear(in_features=20, out_features=20, bias=True)\n    (3): Tanh()\n    (4): Linear(in_features=20, out_features=20, bias=True)\n    (5): Tanh()\n    (6): Linear(in_features=20, out_features=20, bias=True)\n    (7): Tanh()\n    (8): Linear(in_features=20, out_features=20, bias=True)\n    (9): Tanh()\n    (10): Linear(in_features=20, out_features=20, bias=True)\n    (11): Tanh()\n    (12): Linear(in_features=20, out_features=20, bias=True)\n    (13): Tanh()\n    (14): Linear(in_features=20, out_features=20, bias=True)\n    (15): Tanh()\n    (16): Linear(in_features=20, out_features=20, bias=True)\n    (17): Tanh()\n    (18): Linear(in_features=20, out_features=20, bias=True)\n    (19): Tanh()\n    (20): Linear(in_features=20, out_features=1, bias=True)\n  )\n  (loss): MSELoss()\n)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# load data","metadata":{"id":"rGkiaXm9becD"}},{"cell_type":"code","source":"import torch\nimport numpy as np\ndef loadAndPrep(u):\n    x = [i for i in range(201)]\n    t = [i for i in range(1024)]\n    x = torch.tensor(x, dtype=torch.float32)\n    t = torch.tensor(t, dtype=torch.float32)\n    u = torch.tensor(u, dtype=torch.float32)\n    X, T = np.meshgrid(x, t)\n    xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n    idx = np.random.choice(201*1024, 10000, replace=False)\n    xtrain = xtrue[idx, :]\n    utrain = u.flatten()[idx][:, None]\n    device = torch.device(\"cuda\")\n    xtrain = torch.tensor(xtrain, dtype=torch.float32, device=device)\n    xtrue = torch.tensor(xtrue, dtype=torch.float32, device=device)\n    utrain = utrain.to(device)\n    utrue = u.flatten()[:, None]\n    return xtrain, xtrue, utrain, utrue","metadata":{"execution":{"iopub.status.busy":"2025-02-06T02:23:03.891337Z","iopub.execute_input":"2025-02-06T02:23:03.891879Z","iopub.status.idle":"2025-02-06T02:23:03.898368Z","shell.execute_reply.started":"2025-02-06T02:23:03.891850Z","shell.execute_reply":"2025-02-06T02:23:03.897108Z"},"id":"7rMohbkTURuR","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import gc\ndef trainAndLog(u):\n    xtrain, _, utrain, _ = loadAndPrep(u)\n    model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n    loss = model.train_model(xtrain, utrain, epochs=15000)\n    l = model.lambda2.item()\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    return l, loss","metadata":{"execution":{"iopub.status.busy":"2025-02-06T02:23:04.070560Z","iopub.execute_input":"2025-02-06T02:23:04.070879Z","iopub.status.idle":"2025-02-06T02:23:04.075843Z","shell.execute_reply.started":"2025-02-06T02:23:04.070852Z","shell.execute_reply":"2025-02-06T02:23:04.074650Z"},"id":"2FOOLeOZ1kej","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import h5py\nimport random\nimport json\n\nrandom.seed(69)\nd = {}\nwith h5py.File(\"/kaggle/input/burgers-clean/simulation_data.h5\", \"r\") as f:\n    a = random.choices(list(f.keys()), k=50)\n    n = 0\n    for i in a:\n        print(n)\n        d[i] = []\n        d[i].append({\"epsilon\" : f[i][\"epsilon\"][()]})\n        uclean = f[i][\"clean\"][:]\n        pred, loss = trainAndLog(uclean)\n        d[i].append({\"clean\" : [{\"predicted\" : pred, \"loss\" : loss}]})\n        unoisy = f[i][\"noisy\"][:]\n        pred, loss = trainAndLog(unoisy)\n        d[i].append({\"noisy\": [{\"predicted\" : pred, \"loss\" : loss}]})\n        n += 1\n        with open(\"results.json\", \"w\") as g:\n            json.dump(d, g)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-02-06T02:23:39.303777Z","iopub.execute_input":"2025-02-06T02:23:39.304087Z","iopub.status.idle":"2025-02-06T02:23:46.405867Z","shell.execute_reply.started":"2025-02-06T02:23:39.304059Z","shell.execute_reply":"2025-02-06T02:23:46.404627Z"},"id":"piSIjloX1kek","outputId":"51226dbd-bef9-4e27-f831-647d84e002aa","trusted":true},"outputs":[{"name":"stdout","text":"0\nEpoch 0, Loss 0.22437208890914917, Lambda2 (Nu) 0.010001188144087791\nEpoch 0, Loss 0.3579258322715759, Lambda2 (Nu) 0.009996850974857807\n1\nEpoch 0, Loss 0.32747524976730347, Lambda2 (Nu) 0.009999974630773067\nEpoch 0, Loss 0.3455558717250824, Lambda2 (Nu) 0.009993717074394226\n2\nEpoch 0, Loss 0.3950692415237427, Lambda2 (Nu) 0.010007492266595364\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e58c92870ea4>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"epsilon\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epsilon\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0muclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainAndLog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"clean\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"predicted\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0munoisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"noisy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-12f09fd4fe01>\u001b[0m in \u001b[0;36mtrainAndLog\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadAndPrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-eb4848eda9e4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, xtrain, utrain, epochs)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.execute_input":"2025-02-06T00:52:54.30502Z","iopub.status.busy":"2025-02-06T00:52:54.304717Z","iopub.status.idle":"2025-02-06T00:52:54.309405Z","shell.execute_reply":"2025-02-06T00:52:54.308527Z","shell.execute_reply.started":"2025-02-06T00:52:54.304993Z"},"id":"2xmcC-zy1kek","trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}