{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, c):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                (\n",
    "                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n",
    "                    if i % 2 == 0\n",
    "                    else nn.Tanh()\n",
    "                )\n",
    "                for i in range(20)\n",
    "            ]\n",
    "        )\n",
    "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.c = c\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def loss_fn(self, x, u):\n",
    "        u_pred = self.forward(x)\n",
    "        return self.loss(u_pred, u)\n",
    "\n",
    "    def residual_loss(self, xtrain, fhat):\n",
    "        g = xtrain.clone()\n",
    "        g.requires_grad = True\n",
    "\n",
    "        u_pred = self.forward(g) # now I predict u(x,t)\n",
    "\n",
    "        u_x_t = torch.autograd.grad(\n",
    "            u_pred,\n",
    "            g,\n",
    "            torch.ones([xtrain.shape[0], 1]).to(\"cuda\"),\n",
    "            retain_graph=True,\n",
    "            create_graph=True,\n",
    "        )[0] # first derivatives wrt x and t\n",
    "\n",
    "        u_xx_tt = torch.autograd.grad(\n",
    "            u_x_t, g, torch.ones(xtrain.shape).to(\"cuda\"), create_graph=True\n",
    "        )[0] # second derivatives wrt x and t\n",
    "\n",
    "        # u_x = u_x_t[:, [0]]\n",
    "        # u_t = u_x_t[:, [1]]\n",
    "        u_xx = u_xx_tt[:, [0]] # second derivative wrt x\n",
    "        u_tt = u_xx_tt[:, [1]] # second derivative wrt t\n",
    "\n",
    "        # residual = u_tt - c^2 * u_xx\n",
    "        residual = u_tt - self.c ** 2 * u_xx\n",
    "        return self.loss(residual, fhat)        \n",
    "\n",
    "    def total_loss(self, xtrain, utrain, fhat):\n",
    "        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n",
    "    \n",
    "    def train_model(self, xtrain, utrain, epochs=1000):\n",
    "        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.total_loss(xtrain, utrain, fhat)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss {loss.item()}\")\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024,), (201,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 50, 1024)\n",
    "t = np.linspace(0, 2, 201)\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, T = np.meshgrid(x, t)\n",
    "xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "xtrue = torch.tensor(xtrue, dtype=torch.float32, device=\"cuda\")\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def loadAndPrep(u):\n",
    "    idx = np.random.choice(u.flatten().shape[0], 10000, replace=False)\n",
    "    xtrain = xtrue[idx, :]\n",
    "    utrain = u.flatten()[idx][:, None]\n",
    "    utrain = torch.tensor(utrain, dtype=torch.float32).to(device)\n",
    "    return xtrain, utrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "def trainAndLog(u, e):\n",
    "    xtrain, utrain = loadAndPrep(u)\n",
    "    model = PINN(input_size=2, hidden_size=20, output_size=1, c=e).to(\"cuda\")\n",
    "    loss = model.train_model(xtrain, utrain, epochs=5000)\n",
    "    with torch.no_grad():\n",
    "        pred = model(xtrue).cpu().numpy()\n",
    "    l = np.mean((u.flatten() - pred.flatten()) ** 2)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return l, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(69)\n",
    "d = {}\n",
    "with h5py.File(\"data.h5\", \"r\") as f:\n",
    "    a = random.choices(list(f.keys()), k=50)\n",
    "    n = 0\n",
    "    for i in a:\n",
    "        print(n)\n",
    "        e = f[i][\"c\"][()]\n",
    "        uclean = f[i][\"clean\"][:]\n",
    "        mse, loss = trainAndLog(uclean, e)\n",
    "        unoisy = f[i][\"noise\"][:]\n",
    "        mse1, loss1 = trainAndLog(unoisy, e)\n",
    "        d[i] = {\n",
    "            \"clean\" : {\"mse\" : float(mse), \"loss\" : float(loss)},\n",
    "            \"noise\" : {\"mse\" : float(mse1), \"loss\" : float(loss1)}\n",
    "        }\n",
    "        n += 1\n",
    "        with open(\"results.json\", \"w\") as g:\n",
    "            json.dump(d, g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
