{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj6BZ7YFbcg6"
      },
      "source": [
        "# pinn class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-06T00:43:55.956668Z",
          "iopub.status.busy": "2025-02-06T00:43:55.956314Z",
          "iopub.status.idle": "2025-02-06T00:43:55.972346Z",
          "shell.execute_reply": "2025-02-06T00:43:55.971584Z",
          "shell.execute_reply.started": "2025-02-06T00:43:55.95664Z"
        },
        "id": "7zMBM8RvSZ-B",
        "outputId": "c847dc8b-6a3b-4049-8301-2d9972b7e215",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PINN(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=2, out_features=20, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (13): Tanh()\n",
            "    (14): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (15): Tanh()\n",
            "    (16): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (17): Tanh()\n",
            "    (18): Linear(in_features=20, out_features=20, bias=True)\n",
            "    (19): Tanh()\n",
            "    (20): Linear(in_features=20, out_features=1, bias=True)\n",
            "  )\n",
            "  (loss): MSELoss()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(PINN, self).__init__()\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                (\n",
        "                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n",
        "                    if i % 2 == 0\n",
        "                    else nn.Tanh()\n",
        "                )\n",
        "                for i in range(20)\n",
        "            ]\n",
        "        )\n",
        "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.lambda2 = nn.Parameter(\n",
        "            torch.tensor([0.01], dtype=torch.float32, device=\"cuda\")\n",
        "        )\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        self.optimizer.param_groups[0][\"params\"].append(self.lambda2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def loss_fn(self, x, u):\n",
        "        u_pred = self.forward(x)\n",
        "        return self.loss(u_pred, u)\n",
        "\n",
        "    def residual_loss(self, xtrain, fhat):\n",
        "        x = xtrain[:, 0]\n",
        "        t = xtrain[:, 1]\n",
        "        g = xtrain.clone()\n",
        "        g.requires_grad = True\n",
        "        u_pred = self.forward(g)\n",
        "        u_x_t = torch.autograd.grad(\n",
        "            u_pred,\n",
        "            g,\n",
        "            torch.ones([xtrain.shape[0], 1]).to(\"cuda\"),\n",
        "            retain_graph=True,\n",
        "            create_graph=True,\n",
        "        )[0]\n",
        "        u_xx_tt = torch.autograd.grad(\n",
        "            u_x_t, g, torch.ones(xtrain.shape).to(\"cuda\"), create_graph=True\n",
        "        )[0]\n",
        "        u_x = u_x_t[:, [0]]\n",
        "        u_t = u_x_t[:, [1]]\n",
        "        u_xx = u_xx_tt[:, [0]]\n",
        "        return self.loss(u_t + (u_pred * u_x) - (self.lambda2 * u_xx), fhat)\n",
        "\n",
        "    def total_loss(self, xtrain, utrain, fhat):\n",
        "        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n",
        "\n",
        "    def train_model(self, xtrain, utrain, epochs=1000):\n",
        "        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n",
        "        for epoch in range(epochs):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = self.total_loss(xtrain, utrain, fhat)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss {loss.item()}, Lambda2 (Nu) {self.lambda2.item()}\")\n",
        "        return loss.item()\n",
        "\n",
        "\n",
        "model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGkiaXm9becD"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-06T00:38:13.268563Z",
          "iopub.status.busy": "2025-02-06T00:38:13.268243Z",
          "iopub.status.idle": "2025-02-06T00:38:13.274733Z",
          "shell.execute_reply": "2025-02-06T00:38:13.273863Z",
          "shell.execute_reply.started": "2025-02-06T00:38:13.268538Z"
        },
        "id": "7rMohbkTURuR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "def loadAndPrep(u):\n",
        "    x = [i for i in range(201)]\n",
        "    t = [i for i in range(1024)]\n",
        "    x = torch.tensor(x, dtype=torch.float32)\n",
        "    t = torch.tensor(t, dtype=torch.float32)\n",
        "    u = torch.tensor(u, dtype=torch.float32)\n",
        "    X, T = np.meshgrid(x, t)\n",
        "    xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
        "    idx = np.random.choice(201*1024, 10000, replace=False)\n",
        "    xtrain = xtrue[idx, :]\n",
        "    utrain = u.flatten()[idx][:, None]\n",
        "    device = torch.device(\"cuda\")\n",
        "    xtrain = torch.tensor(xtrain, dtype=torch.float32, device=device)\n",
        "    xtrue = torch.tensor(xtrue, dtype=torch.float32, device=device)\n",
        "    utrain = utrain.to(device)\n",
        "    utrue = u.flatten()[:, None]\n",
        "    return xtrain, xtrue, utrain, utrue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-06T00:51:55.464696Z",
          "iopub.status.busy": "2025-02-06T00:51:55.464317Z",
          "iopub.status.idle": "2025-02-06T00:51:55.46939Z",
          "shell.execute_reply": "2025-02-06T00:51:55.468428Z",
          "shell.execute_reply.started": "2025-02-06T00:51:55.46467Z"
        },
        "id": "2FOOLeOZ1kej",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "def trainAndLog(u):\n",
        "    xtrain, _, utrain, _ = loadAndPrep(u)\n",
        "    model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n",
        "    loss = model.train_model(xtrain, utrain, epochs=20000)\n",
        "    l = model.lambda2.item()\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    return l, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-02-06T00:51:56.821982Z",
          "iopub.status.busy": "2025-02-06T00:51:56.821686Z",
          "iopub.status.idle": "2025-02-06T00:52:45.052316Z",
          "shell.execute_reply": "2025-02-06T00:52:45.051564Z",
          "shell.execute_reply.started": "2025-02-06T00:51:56.821957Z"
        },
        "id": "piSIjloX1kek",
        "outputId": "51226dbd-bef9-4e27-f831-647d84e002aa",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 0, Loss 0.214645653963089, Lambda2 (Nu) 0.010005610063672066\n",
            "Epoch 1000, Loss 0.209650918841362, Lambda2 (Nu) 0.05669505149126053\n",
            "Epoch 2000, Loss 0.20906195044517517, Lambda2 (Nu) -0.04262608662247658\n",
            "Epoch 3000, Loss 0.20836541056632996, Lambda2 (Nu) 0.06333594769239426\n",
            "Epoch 4000, Loss 0.20821015536785126, Lambda2 (Nu) 0.09430645406246185\n",
            "Epoch 5000, Loss 0.20817041397094727, Lambda2 (Nu) 0.08547811210155487\n",
            "Epoch 6000, Loss 0.2080112099647522, Lambda2 (Nu) 0.07235059142112732\n",
            "Epoch 7000, Loss 0.21048443019390106, Lambda2 (Nu) 0.009417339228093624\n",
            "Epoch 8000, Loss 0.2094377726316452, Lambda2 (Nu) 0.004867367912083864\n",
            "Epoch 9000, Loss 0.20890945196151733, Lambda2 (Nu) 0.003238480072468519\n",
            "Epoch 10000, Loss 0.2089010626077652, Lambda2 (Nu) 0.004173026420176029\n",
            "Epoch 11000, Loss 0.20818394422531128, Lambda2 (Nu) 0.05283937603235245\n",
            "Epoch 12000, Loss 0.20792633295059204, Lambda2 (Nu) 0.08382382243871689\n",
            "Epoch 13000, Loss 0.20770277082920074, Lambda2 (Nu) 0.0717075765132904\n",
            "Epoch 14000, Loss 0.20771336555480957, Lambda2 (Nu) 0.06388766318559647\n",
            "Epoch 15000, Loss 0.20752254128456116, Lambda2 (Nu) 0.056998781859874725\n",
            "Epoch 16000, Loss 0.20742709934711456, Lambda2 (Nu) 0.05216803029179573\n",
            "Epoch 17000, Loss 0.20738540589809418, Lambda2 (Nu) 0.046264223754405975\n",
            "Epoch 18000, Loss 0.2072339951992035, Lambda2 (Nu) 0.0414578802883625\n",
            "Epoch 19000, Loss 0.2072136402130127, Lambda2 (Nu) 0.03418953716754913\n",
            "Epoch 0, Loss 0.24731464684009552, Lambda2 (Nu) 0.00999735202640295\n",
            "Epoch 1000, Loss 0.24473124742507935, Lambda2 (Nu) -0.023329490795731544\n",
            "Epoch 2000, Loss 0.2442154586315155, Lambda2 (Nu) -0.030805300921201706\n",
            "Epoch 3000, Loss 0.24353979527950287, Lambda2 (Nu) 0.028794070705771446\n",
            "Epoch 4000, Loss 0.2436216175556183, Lambda2 (Nu) -0.00477575184777379\n",
            "Epoch 5000, Loss 0.24310901761054993, Lambda2 (Nu) -0.00498789269477129\n",
            "Epoch 6000, Loss 0.24298594892024994, Lambda2 (Nu) 0.009810277260839939\n",
            "Epoch 7000, Loss 0.2424175888299942, Lambda2 (Nu) 0.014980584383010864\n",
            "Epoch 8000, Loss 0.24220643937587738, Lambda2 (Nu) 0.0033837829250842333\n",
            "Epoch 9000, Loss 0.24185699224472046, Lambda2 (Nu) -0.0024036841932684183\n",
            "Epoch 10000, Loss 0.24198098480701447, Lambda2 (Nu) -0.0013602792751044035\n",
            "Epoch 11000, Loss 0.24164243042469025, Lambda2 (Nu) -0.0014081508852541447\n",
            "Epoch 12000, Loss 0.24193088710308075, Lambda2 (Nu) -0.004345926456153393\n",
            "Epoch 13000, Loss 0.24128130078315735, Lambda2 (Nu) -0.002422708086669445\n",
            "Epoch 14000, Loss 0.2411714345216751, Lambda2 (Nu) -0.0036673082504421473\n",
            "Epoch 15000, Loss 0.24064160883426666, Lambda2 (Nu) -0.0033027236349880695\n",
            "Epoch 16000, Loss 0.24523988366127014, Lambda2 (Nu) 0.00080865592462942\n",
            "Epoch 17000, Loss 0.24305285513401031, Lambda2 (Nu) 0.003074516309425235\n",
            "Epoch 18000, Loss 0.241643026471138, Lambda2 (Nu) 0.0012413682416081429\n",
            "Epoch 19000, Loss 0.24103407561779022, Lambda2 (Nu) 7.92493301560171e-05\n",
            "1\n",
            "Epoch 0, Loss 0.3309432566165924, Lambda2 (Nu) 0.009996505454182625\n",
            "Epoch 1000, Loss 0.3110484182834625, Lambda2 (Nu) 0.00871191918849945\n",
            "Epoch 2000, Loss 0.3097681999206543, Lambda2 (Nu) 0.12154883146286011\n",
            "Epoch 3000, Loss 0.3090055286884308, Lambda2 (Nu) 0.050425708293914795\n",
            "Epoch 4000, Loss 0.30870217084884644, Lambda2 (Nu) 0.09246895462274551\n",
            "Epoch 5000, Loss 0.30825328826904297, Lambda2 (Nu) 0.10071560740470886\n",
            "Epoch 6000, Loss 0.30799365043640137, Lambda2 (Nu) 0.1095457449555397\n",
            "Epoch 7000, Loss 0.3079299032688141, Lambda2 (Nu) 0.12853410840034485\n",
            "Epoch 8000, Loss 0.3083186745643616, Lambda2 (Nu) 0.10441017895936966\n",
            "Epoch 9000, Loss 0.30778777599334717, Lambda2 (Nu) 0.04792768880724907\n",
            "Epoch 10000, Loss 0.3075231909751892, Lambda2 (Nu) 0.022230638191103935\n",
            "Epoch 11000, Loss 0.3073055148124695, Lambda2 (Nu) 0.0007827660301700234\n",
            "Epoch 12000, Loss 0.30811047554016113, Lambda2 (Nu) -0.001881226198747754\n",
            "Epoch 13000, Loss 0.30659037828445435, Lambda2 (Nu) 0.0013728964840993285\n",
            "Epoch 14000, Loss 0.3064965605735779, Lambda2 (Nu) 0.0003419840068090707\n",
            "Epoch 15000, Loss 0.30634891986846924, Lambda2 (Nu) 0.00018144914065487683\n",
            "Epoch 16000, Loss 0.3063667118549347, Lambda2 (Nu) 0.0008963941945694387\n",
            "Epoch 17000, Loss 0.30656176805496216, Lambda2 (Nu) -0.006109230685979128\n",
            "Epoch 18000, Loss 0.30580934882164, Lambda2 (Nu) -0.00454659853130579\n",
            "Epoch 19000, Loss 0.30944427847862244, Lambda2 (Nu) 0.04274687170982361\n",
            "Epoch 0, Loss 0.351737916469574, Lambda2 (Nu) 0.010000710375607014\n",
            "Epoch 1000, Loss 0.3340674042701721, Lambda2 (Nu) 0.04183930158615112\n",
            "Epoch 2000, Loss 0.3326314091682434, Lambda2 (Nu) -0.011368535459041595\n",
            "Epoch 3000, Loss 0.3320102393627167, Lambda2 (Nu) -0.010598286986351013\n",
            "Epoch 4000, Loss 0.33134201169013977, Lambda2 (Nu) -0.007233276031911373\n",
            "Epoch 5000, Loss 0.32952359318733215, Lambda2 (Nu) -0.004801447037607431\n",
            "Epoch 6000, Loss 0.32886719703674316, Lambda2 (Nu) -0.007593952119350433\n",
            "Epoch 7000, Loss 0.3296189606189728, Lambda2 (Nu) -0.006504713091999292\n",
            "Epoch 8000, Loss 0.3267078697681427, Lambda2 (Nu) -0.008098538033664227\n",
            "Epoch 9000, Loss 0.3259083926677704, Lambda2 (Nu) -0.009103343822062016\n",
            "Epoch 10000, Loss 0.3357928395271301, Lambda2 (Nu) -0.00939138513058424\n",
            "Epoch 11000, Loss 0.35168689489364624, Lambda2 (Nu) -0.0033275880850851536\n",
            "Epoch 12000, Loss 0.32706549763679504, Lambda2 (Nu) -0.0073287514969706535\n",
            "Epoch 13000, Loss 0.3255394399166107, Lambda2 (Nu) -0.007030864246189594\n",
            "Epoch 14000, Loss 0.324358195066452, Lambda2 (Nu) -0.004282184410840273\n",
            "Epoch 15000, Loss 0.3235284686088562, Lambda2 (Nu) -0.001847987063229084\n",
            "Epoch 16000, Loss 0.32262808084487915, Lambda2 (Nu) -0.0010409707901999354\n",
            "Epoch 17000, Loss 0.3252015709877014, Lambda2 (Nu) -0.000533723330590874\n",
            "Epoch 18000, Loss 0.3234744668006897, Lambda2 (Nu) -0.0012141024926677346\n",
            "Epoch 19000, Loss 0.32221218943595886, Lambda2 (Nu) -0.0002680432517081499\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import random\n",
        "random.seed(69)\n",
        "d = {}\n",
        "with h5py.File(\"simulation_data.h5\", \"r\") as f:\n",
        "    a = random.choices(list(f.keys()), k=50)\n",
        "    n = 0\n",
        "    for i in a[:2]:\n",
        "        print(n)\n",
        "        d[i] = []\n",
        "        d[i].append({\"epsilon\" : f[i][\"epsilon\"][()]})\n",
        "        uclean = f[i][\"clean\"][:]\n",
        "        pred, loss = trainAndLog(uclean)\n",
        "        d[i].append({\"clean\" : [{\"predicted\" : pred, \"loss\" : loss}]})\n",
        "        unoisy = f[i][\"noisy\"][:]\n",
        "        pred, loss = trainAndLog(unoisy)\n",
        "        d[i].append({\"noisy\": [{\"predicted\" : pred, \"loss\" : loss}]})\n",
        "        n += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-06T00:52:54.30502Z",
          "iopub.status.busy": "2025-02-06T00:52:54.304717Z",
          "iopub.status.idle": "2025-02-06T00:52:54.309405Z",
          "shell.execute_reply": "2025-02-06T00:52:54.308527Z",
          "shell.execute_reply.started": "2025-02-06T00:52:54.304993Z"
        },
        "id": "2xmcC-zy1kek",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(\"results.json\", \"w\") as f:\n",
        "    json.dump(d, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "burger-pinn-metrics",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 6553954,
          "sourceId": 10602798,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30840,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
