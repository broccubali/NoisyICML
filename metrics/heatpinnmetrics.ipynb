{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10627805,"sourceType":"datasetVersion","datasetId":6580247}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-06T03:17:00.715633Z","iopub.execute_input":"2025-02-06T03:17:00.715941Z","iopub.status.idle":"2025-02-06T03:17:00.720032Z","shell.execute_reply.started":"2025-02-06T03:17:00.715912Z","shell.execute_reply":"2025-02-06T03:17:00.718953Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom tqdm import tqdm\n\n\nclass PINN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(PINN, self).__init__()\n        self.layers = nn.ModuleList(\n            [\n                (\n                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n                    if i % 2 == 0\n                    else nn.Tanh()\n                )\n                for i in range(20)\n            ]\n        )\n        self.layers.append(nn.Linear(hidden_size, output_size))\n        self.loss = nn.MSELoss()\n        self.alpha = nn.Parameter(torch.tensor([0.1], requires_grad=True).to(\"cuda\"))\n        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\n    def loss_fn(self, x, u):\n        u_pred = self.forward(x)\n        return self.loss(u_pred, u)\n\n    def residual_loss(self, xtrain, fhat):\n        x = xtrain[:, 0]\n        t = xtrain[:, 1]\n        g = xtrain.clone()\n        g.requires_grad = True\n        u_pred = self.forward(g)\n        u_x_t = torch.autograd.grad(\n            u_pred, g, torch.ones_like(u_pred), create_graph=True\n        )[0]\n        u_x, u_t = u_x_t[:, 0], u_x_t[:, 1]\n        u_xx = torch.autograd.grad(u_x, g, torch.ones_like(u_x), create_graph=True)[0][\n            :, 0\n        ]\n        residual = u_t - self.alpha * u_xx\n        return self.loss(residual, fhat)\n\n    def total_loss(self, xtrain, utrain, fhat):\n        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n\n    def train_model(self, xtrain, utrain, epochs=1000):\n        fhat = torch.zeros(xtrain.shape[0], 1, device=\"cuda\")\n        for epoch in tqdm(range(epochs)):\n            self.optimizer.zero_grad()\n            loss = self.total_loss(xtrain, utrain, fhat)\n            loss.backward()\n            self.optimizer.step()\n            if epoch % 1000 == 0:\n                print(f\"Epoch {epoch}, Loss {loss.item()}, alpha {self.alpha.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:57:46.238661Z","iopub.execute_input":"2025-02-06T07:57:46.238935Z","iopub.status.idle":"2025-02-06T07:57:46.248068Z","shell.execute_reply.started":"2025-02-06T07:57:46.238915Z","shell.execute_reply":"2025-02-06T07:57:46.247023Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:57:48.781716Z","iopub.execute_input":"2025-02-06T07:57:48.781988Z","iopub.status.idle":"2025-02-06T07:57:48.790085Z","shell.execute_reply.started":"2025-02-06T07:57:48.781965Z","shell.execute_reply":"2025-02-06T07:57:48.789210Z"}},"outputs":[{"name":"stdout","text":"PINN(\n  (layers): ModuleList(\n    (0): Linear(in_features=2, out_features=20, bias=True)\n    (1): Tanh()\n    (2): Linear(in_features=20, out_features=20, bias=True)\n    (3): Tanh()\n    (4): Linear(in_features=20, out_features=20, bias=True)\n    (5): Tanh()\n    (6): Linear(in_features=20, out_features=20, bias=True)\n    (7): Tanh()\n    (8): Linear(in_features=20, out_features=20, bias=True)\n    (9): Tanh()\n    (10): Linear(in_features=20, out_features=20, bias=True)\n    (11): Tanh()\n    (12): Linear(in_features=20, out_features=20, bias=True)\n    (13): Tanh()\n    (14): Linear(in_features=20, out_features=20, bias=True)\n    (15): Tanh()\n    (16): Linear(in_features=20, out_features=20, bias=True)\n    (17): Tanh()\n    (18): Linear(in_features=20, out_features=20, bias=True)\n    (19): Tanh()\n    (20): Linear(in_features=20, out_features=1, bias=True)\n  )\n  (loss): MSELoss()\n)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nimport numpy as np\ndef loadAndPrep(u):\n    x = [i for i in range(201)]\n    t = [i for i in range(1024)]\n    x = torch.tensor(x, dtype=torch.float32)\n    t = torch.tensor(t, dtype=torch.float32)\n    u = torch.tensor(u, dtype=torch.float32)\n    X, T = np.meshgrid(x, t)\n    xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n    idx = np.random.choice(u.flatten().shape[0], 10000, replace=False)\n    xtrain = xtrue[idx, :]\n    utrain = u.flatten()[idx][:, None]\n    device = torch.device(\"cuda\")\n    xtrain = torch.tensor(xtrain, dtype=torch.float32, device=device)\n    xtrue = torch.tensor(xtrue, dtype=torch.float32, device=device)\n    utrain = utrain.to(device)\n    utrue = u.flatten()[:, None]\n    return xtrain, xtrue, utrain, utrue","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T08:00:58.441680Z","iopub.execute_input":"2025-02-06T08:00:58.441954Z","iopub.status.idle":"2025-02-06T08:00:58.447934Z","shell.execute_reply.started":"2025-02-06T08:00:58.441933Z","shell.execute_reply":"2025-02-06T08:00:58.446978Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import gc\ndef trainAndLog(u):\n    xtrain, _, utrain, _ = loadAndPrep(u)\n    model = PINN(input_size=2, hidden_size=20, output_size=1).to(\"cuda\")\n    loss = model.train_model(xtrain, utrain, epochs=15000)\n    alpha = model.alpha.item()\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    return alpha, loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T08:00:59.427032Z","iopub.execute_input":"2025-02-06T08:00:59.427328Z","iopub.status.idle":"2025-02-06T08:00:59.431842Z","shell.execute_reply.started":"2025-02-06T08:00:59.427305Z","shell.execute_reply":"2025-02-06T08:00:59.431192Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import h5py\nwith h5py.File(\"/kaggle/input/heateq/data.h5\", \"r\") as f:\n    print(f[\"0\"].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T08:00:59.743191Z","iopub.execute_input":"2025-02-06T08:00:59.743430Z","iopub.status.idle":"2025-02-06T08:00:59.763214Z","shell.execute_reply.started":"2025-02-06T08:00:59.743411Z","shell.execute_reply":"2025-02-06T08:00:59.762483Z"}},"outputs":[{"name":"stdout","text":"<KeysViewHDF5 ['alpha', 'u', 'u_noisy']>\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import random\nimport json\n\nrandom.seed(69)\nd = {}\nwith h5py.File(\"/kaggle/input/heateq/data.h5\", \"r\") as f:\n    a = random.choices(list(f.keys()), k=50)\n    n = 0\n    for i in a:\n        print(n)\n        d[i] = []\n        d[i].append({\"alpha\" : f[i][\"alpha\"][()]})\n        uclean = f[i][\"u\"][:]\n        pred, loss = trainAndLog(uclean)\n        d[i].append({\"clean\" : [{\"predicted\" : pred, \"loss\" : loss}]})\n        unoisy = f[i][\"u_noisy\"][:]\n        pred, loss = trainAndLog(unoisy)\n        d[i].append({\"noisy\": [{\"predicted\" : pred, \"loss\" : loss}]})\n        n += 1\n        with open(\"/kaggle/working/results_heat.json\", \"w\") as g:\n            json.dump(d, g)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T08:01:01.317586Z","iopub.execute_input":"2025-02-06T08:01:01.317863Z"}},"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/15000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([10000, 1])) that is different to the input size (torch.Size([10000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n  0%|          | 8/15000 [00:01<26:26,  9.45it/s]  ","output_type":"stream"},{"name":"stdout","text":"Epoch 0, Loss 0.02058250643312931, alpha 0.09999560564756393\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 1015/15000 [00:15<03:14, 71.93it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1000, Loss 0.004113102797418833, alpha -0.3004153370857239\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2015/15000 [00:29<03:09, 68.35it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2000, Loss 0.0040853568352758884, alpha -0.2824457287788391\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3015/15000 [00:43<02:47, 71.49it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3000, Loss 0.0040944465436041355, alpha -0.23705197870731354\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4015/15000 [00:57<02:32, 71.94it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4000, Loss 0.004054611548781395, alpha -0.14734965562820435\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5015/15000 [01:10<02:17, 72.38it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5000, Loss 0.004032946191728115, alpha -0.07986283302307129\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6016/15000 [01:24<02:04, 72.02it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 6000, Loss 0.004030030220746994, alpha -0.046728458255529404\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7016/15000 [01:38<01:51, 71.80it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 7000, Loss 0.004048523493111134, alpha 0.01958676427602768\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8010/15000 [01:52<01:37, 71.99it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 8000, Loss 0.004036420956254005, alpha 0.028354108333587646\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9010/15000 [02:06<01:22, 72.26it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 9000, Loss 0.004005939234048128, alpha 0.04279227927327156\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10009/15000 [02:20<01:11, 69.35it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10000, Loss 0.0039979214780032635, alpha 0.026728669181466103\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 11010/15000 [02:34<00:54, 72.59it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 11000, Loss 0.004013231955468655, alpha 0.04818347468972206\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 12010/15000 [02:47<00:41, 72.57it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 12000, Loss 0.004012058023363352, alpha 0.06064805015921593\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 13010/15000 [03:01<00:27, 72.34it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 13000, Loss 0.003943726420402527, alpha -0.09146308153867722\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 14010/15000 [03:15<00:13, 72.34it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 14000, Loss 0.003885008627548814, alpha -0.010270650498569012\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15000/15000 [03:29<00:00, 71.64it/s]\n  0%|          | 16/15000 [00:00<03:27, 72.29it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 0, Loss 0.3438999652862549, alpha 0.09995407611131668\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 1016/15000 [00:14<03:15, 71.66it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1000, Loss 0.11207265406847, alpha 0.4905678629875183\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 2016/15000 [00:28<03:00, 71.78it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 2000, Loss 0.11191622167825699, alpha 0.34075474739074707\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 3016/15000 [00:41<02:47, 71.72it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3000, Loss 0.11175399273633957, alpha 0.19590972363948822\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 4016/15000 [00:55<02:32, 71.80it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 4000, Loss 0.11163891851902008, alpha 0.10582050681114197\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 5016/15000 [01:09<02:18, 71.99it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5000, Loss 0.11144500225782394, alpha 0.04505152627825737\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 6016/15000 [01:23<02:05, 71.61it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 6000, Loss 0.11132614314556122, alpha 0.00420587370172143\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 7016/15000 [01:37<01:51, 71.76it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 7000, Loss 0.11115804314613342, alpha -0.0020699661690741777\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 8016/15000 [01:51<01:37, 71.59it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 8000, Loss 0.11106541007757187, alpha -0.0010996360797435045\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 9016/15000 [02:05<01:23, 71.66it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 9000, Loss 0.11094319820404053, alpha -0.008793833665549755\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 10016/15000 [02:19<01:09, 71.65it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10000, Loss 0.11083211749792099, alpha -0.011278800666332245\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 10833/15000 [02:30<00:57, 71.89it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}