{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:18:45.814144Z",
     "iopub.status.busy": "2025-02-07T16:18:45.813862Z",
     "iopub.status.idle": "2025-02-07T16:18:48.814029Z",
     "shell.execute_reply": "2025-02-07T16:18:48.813168Z",
     "shell.execute_reply.started": "2025-02-07T16:18:45.814120Z"
    },
    "id": "hXpx2YMgJ74F",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, alpha):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                (\n",
    "                    nn.Linear(input_size if i == 0 else hidden_size, hidden_size)\n",
    "                    if i % 2 == 0\n",
    "                    else nn.Tanh()\n",
    "                )\n",
    "                for i in range(20)\n",
    "            ]\n",
    "        )\n",
    "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.alpha = alpha\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=5e-3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def loss_fn(self, x, u):\n",
    "        u_pred = self.forward(x)\n",
    "        return self.loss(u_pred, u)\n",
    "\n",
    "    def residual_loss(self, xtrain, fhat):\n",
    "        g = xtrain.clone()\n",
    "        g.requires_grad = True\n",
    "        u_pred = self.forward(g)\n",
    "        u_x_t = torch.autograd.grad(\n",
    "            u_pred, g, torch.ones_like(u_pred), create_graph=True\n",
    "        )[0]\n",
    "        u_x, u_t = u_x_t[:, 0], u_x_t[:, 1]\n",
    "        u_xx = torch.autograd.grad(u_x, g, torch.ones_like(u_x), create_graph=True)[0][\n",
    "            :, 0\n",
    "        ]\n",
    "        residual = u_t - self.alpha * u_xx\n",
    "        return self.loss(residual, fhat)\n",
    "\n",
    "    def total_loss(self, xtrain, utrain, fhat):\n",
    "        return self.loss_fn(xtrain, utrain) + self.residual_loss(xtrain, fhat)\n",
    "\n",
    "    def train_model(self, xtrain, utrain, epochs=1000):\n",
    "        fhat = torch.zeros(xtrain.shape[0], device=\"cuda\")\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.total_loss(xtrain, utrain, fhat)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss {loss.item()}\")\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:18:48.815813Z",
     "iopub.status.busy": "2025-02-07T16:18:48.815390Z",
     "iopub.status.idle": "2025-02-07T16:18:48.944865Z",
     "shell.execute_reply": "2025-02-07T16:18:48.944072Z",
     "shell.execute_reply.started": "2025-02-07T16:18:48.815780Z"
    },
    "id": "CY2GTmWGJ74M",
    "outputId": "d2449015-8316-4cc2-9dbd-d4325472d110",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50,), (500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "L = 1.0\n",
    "Nx = 50\n",
    "dx = L / Nx\n",
    "T = 0.2\n",
    "Nt = 500\n",
    "dt = T / Nt\n",
    "x = np.linspace(0, L, Nx)\n",
    "t = np.linspace(0, T, Nt)\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:18:48.946603Z",
     "iopub.status.busy": "2025-02-07T16:18:48.946198Z",
     "iopub.status.idle": "2025-02-07T16:18:48.951434Z",
     "shell.execute_reply": "2025-02-07T16:18:48.950671Z",
     "shell.execute_reply.started": "2025-02-07T16:18:48.946580Z"
    },
    "id": "kqe0Ao7BJ74R",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X, T = np.meshgrid(x, t)\n",
    "xtrue = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "xtrue = torch.tensor(xtrue, dtype=torch.float32, device=\"cuda\")\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:18:48.952556Z",
     "iopub.status.busy": "2025-02-07T16:18:48.952308Z",
     "iopub.status.idle": "2025-02-07T16:18:48.965153Z",
     "shell.execute_reply": "2025-02-07T16:18:48.964387Z",
     "shell.execute_reply.started": "2025-02-07T16:18:48.952537Z"
    },
    "id": "nXobZ5eiJ74T",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def loadAndPrep(u):\n",
    "    idx = np.random.choice(u.flatten().shape[0], 10000, replace=False)\n",
    "    global xtrue\n",
    "    xtrain = xtrue[idx, :]\n",
    "    utrain = u.flatten()[idx][:, None]\n",
    "    utrain = torch.tensor(utrain, dtype=torch.float32, device=device)\n",
    "    return xtrain, utrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-07T16:18:48.966251Z",
     "iopub.status.busy": "2025-02-07T16:18:48.965995Z",
     "iopub.status.idle": "2025-02-07T16:18:48.981111Z",
     "shell.execute_reply": "2025-02-07T16:18:48.980398Z",
     "shell.execute_reply.started": "2025-02-07T16:18:48.966222Z"
    },
    "id": "hlZf7rfjJ74X",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "def trainAndLog(u, e, utrue):\n",
    "    xtrain, utrain = loadAndPrep(u)\n",
    "    model = PINN(input_size=2, hidden_size=20, output_size=1, alpha=e).to(\"cuda\")\n",
    "    loss = model.train_model(xtrain, utrain, epochs=5000)\n",
    "    with torch.no_grad():\n",
    "        u_pred = model(xtrue).cpu().numpy()\n",
    "        mse = np.mean((u_pred - utrue.flatten()[:, None]) ** 2)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-02-07T16:19:09.860Z",
     "iopub.execute_input": "2025-02-07T16:18:48.982116Z",
     "iopub.status.busy": "2025-02-07T16:18:48.981844Z"
    },
    "id": "8NfBhoGNJ74c",
    "outputId": "cb04b4d0-8459-4096-a915-6e275c7589f9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "random.seed(69)\n",
    "d = {}\n",
    "with h5py.File(\"data.h5\", \"r\") as f:\n",
    "    a = random.choices(list(f.keys()), k=50)\n",
    "    n = 0\n",
    "    for i in a:\n",
    "        print(n)\n",
    "        e = f[i][\"alpha\"][()]\n",
    "        print(e)\n",
    "        uclean = f[i][\"u\"][:].T\n",
    "        loss, mse = trainAndLog(uclean, e, uclean)\n",
    "        unoisy = f[i][\"u_noisy\"][:]\n",
    "        loss1, mse1 = trainAndLog(unoisy, e, uclean)\n",
    "        d[i] = {\n",
    "            \"clean\": {\"loss\": float(loss), \"mse\": float(mse)},\n",
    "            \"noisy\": {\"loss\": float(loss1), \"mse\": float(mse1)},\n",
    "        }\n",
    "        n += 1\n",
    "        with open(\"results.json\", \"w\") as g:\n",
    "            json.dump(d, g)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "heat-pinn-metrics",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6580247,
     "sourceId": 10627805,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
